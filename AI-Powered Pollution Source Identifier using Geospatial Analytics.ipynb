{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ff01b1a-6cbf-49dc-b69d-3228969c5c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30e6f555-c533-4165-aa32-b8d01ed2dc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = pd.read_csv(r\"D:\\AI-EnviroProject\\india_locations.csv\")\n",
    "air = pd.read_csv(r\"D:\\AI-EnviroProject\\india_air_quality.csv\")\n",
    "weather = pd.read_csv(r\"D:\\AI-EnviroProject\\india_weather.csv\")\n",
    "features = pd.read_csv(r\"D:\\AI-EnviroProject\\india_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d081d57-6b3e-455b-92b7-30edb9261cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.drop_duplicates(inplace=True)\n",
    "air.drop_duplicates(inplace=True)\n",
    "weather.drop_duplicates(inplace=True)\n",
    "features.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dadb61f8-b727-4d4f-80ff-3c20c8a2dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = locations[\n",
    "    (locations['latitude'].between(-90, 90)) &\n",
    "    (locations['longitude'].between(-180, 180))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44dca241-304c-4f3a-aee2-2e6325cadf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows\n",
    "locations.drop_duplicates(inplace=True)\n",
    "air.drop_duplicates(inplace=True)\n",
    "weather.drop_duplicates(inplace=True)\n",
    "features.drop_duplicates(inplace=True)\n",
    "\n",
    "# Remove invalid latitude/longitude\n",
    "locations = locations[(locations['latitude'].between(-90,90)) & (locations['longitude'].between(-180,180))]\n",
    "weather = weather[(weather['latitude'].between(-90,90)) & (weather['longitude'].between(-180,180))]\n",
    "\n",
    "# Remove negative or invalid pollution values\n",
    "pollution_cols = ['PM25 AQ', 'PM10 AQ', 'CO AQ', 'NO2 AQ', 'SO2 AQ', 'O3 AQ']\n",
    "air = air[(air[pollution_cols] >= 0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6245e4ad-59e3-4bf2-970f-24a48b661629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Module 2: Handle Missing Values ---\n",
    "\n",
    "# 1️⃣ Interpolate missing air quality values\n",
    "pollution_cols = ['PM25 AQ', 'PM10 AQ', 'CO AQ', 'NO2 AQ', 'SO2 AQ', 'O3 AQ']\n",
    "air[pollution_cols] = air[pollution_cols].interpolate()\n",
    "\n",
    "# 2️⃣ Fill missing weather values with median (numeric only)\n",
    "numeric_weather_cols = ['temperature','humidity','wind_speed','wind_deg']\n",
    "weather[numeric_weather_cols] = weather[numeric_weather_cols].fillna(weather[numeric_weather_cols].median())\n",
    "\n",
    "# 3️⃣ Fill missing numeric features in location/features dataset\n",
    "numeric_features = features.select_dtypes(include=np.number).columns\n",
    "features[numeric_features] = features[numeric_features].fillna(features[numeric_features].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c73f100a-a9c0-4d34-8adf-86a624847d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize Timestamps & GPS\n",
    "locations['latitude'] = locations['latitude'].astype(float)\n",
    "locations['longitude'] = locations['longitude'].astype(float)\n",
    "weather['latitude'] = weather['latitude'].astype(float)\n",
    "weather['longitude'] = weather['longitude'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2caf426-5913-4219-8075-6e72c7ecc3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- STEP 3: Normalize Air Quality & Weather -----------------\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize pollution\n",
    "air[pollution_cols] = scaler.fit_transform(air[pollution_cols])\n",
    "\n",
    "# Normalize numeric weather columns\n",
    "weather[numeric_weather_cols] = scaler.fit_transform(weather[numeric_weather_cols])\n",
    "\n",
    "# ----------------- STEP 4: Temporal Features (from weather) -----------------\n",
    "weather['timestamp'] = pd.to_datetime(weather['timestamp'])\n",
    "weather['hour'] = weather['timestamp'].dt.hour\n",
    "weather['day_of_week'] = weather['timestamp'].dt.dayofweek\n",
    "weather['month'] = weather['timestamp'].dt.month\n",
    "weather['season'] = weather['month'] % 12 // 3 + 1  # 1: Winter, 2: Spring, 3: Summer, 4: Fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c86c595-5626-4da6-b7c6-1b3c638db5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7050, 37)\n",
      "       city_x   PM25 AQ PM25 AQI Category   PM10 AQ PM10 AQI Category  \\\n",
      "0      Mumbai  0.243907          Moderate  0.220635          Moderate   \n",
      "1   New Delhi  0.347064          Moderate  0.349750              Poor   \n",
      "2        Pune  0.234645          Moderate  0.209854          Moderate   \n",
      "3  Shrirampur  0.080488              Good  0.077687              Good   \n",
      "4       Vaduj  0.273963          Moderate  0.248072          Moderate   \n",
      "\n",
      "      CO AQ CO AQI Category    NO2 AQ NO2 AQI Category    SO2 AQ  ...  \\\n",
      "0  0.118402       Very Poor  0.015383             Good  0.104827  ...   \n",
      "1  0.291592          Severe  0.234147             Good  0.040097  ...   \n",
      "2  0.119842       Very Poor  0.035110             Good  0.048713  ...   \n",
      "3  0.095073       Very Poor  0.139032             Good  0.085276  ...   \n",
      "4  0.157308          Severe  0.112729             Good  0.049265  ...   \n",
      "\n",
      "  Farmland_Count  Landfill_Count Dump_Site_Count  Distance_to_Nearest_Road_m  \\\n",
      "0            2.0             0.0             0.0                       23.60   \n",
      "1            0.0             0.0             3.0                        1.50   \n",
      "2            2.0             0.0             1.0                       24.72   \n",
      "3           11.0             0.0             0.0                        0.00   \n",
      "4            0.0             0.0             0.0                        0.76   \n",
      "\n",
      "   Distance_to_Nearest_Industrial_m  Distance_to_Nearest_Farmland_m  \\\n",
      "0                             51.03                         1878.86   \n",
      "1                            916.48                          814.33   \n",
      "2                           1355.70                         1793.35   \n",
      "3                           1045.90                          814.50   \n",
      "4                            916.48                          814.33   \n",
      "\n",
      "   Distance_to_Nearest_Landfill_m  Distance_to_Nearest_Dump_m   latitude  \\\n",
      "0                          894.22                      340.40  19.054999   \n",
      "1                          894.22                     2068.80  28.613895   \n",
      "2                          894.22                      563.07  18.521374   \n",
      "3                          894.22                      340.40  19.619971   \n",
      "4                          894.22                      340.40  17.595082   \n",
      "\n",
      "   longitude  \n",
      "0  72.869203  \n",
      "1  77.209006  \n",
      "2  73.854507  \n",
      "3  74.654694  \n",
      "4  74.450466  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "city_x                              2025\n",
      "PM25 AQ                                0\n",
      "PM25 AQI Category                      0\n",
      "PM10 AQ                                0\n",
      "PM10 AQI Category                      0\n",
      "CO AQ                                  0\n",
      "CO AQI Category                        0\n",
      "NO2 AQ                                 0\n",
      "NO2 AQI Category                       0\n",
      "SO2 AQ                                 0\n",
      "SO2 AQI Category                       0\n",
      "O3 AQ                                  0\n",
      "O3 AQI Category                        0\n",
      "AQI                                    0\n",
      "location_id                            0\n",
      "temperature                            0\n",
      "humidity                               0\n",
      "wind_speed                             0\n",
      "wind_deg                               0\n",
      "timestamp                              0\n",
      "hour                                   0\n",
      "day_of_week                            0\n",
      "month                                  0\n",
      "season                                 0\n",
      "city_y                              2025\n",
      "Road_Count                          2025\n",
      "Industrial_Count                    2025\n",
      "Farmland_Count                      2025\n",
      "Landfill_Count                      2025\n",
      "Dump_Site_Count                     2025\n",
      "Distance_to_Nearest_Road_m          2025\n",
      "Distance_to_Nearest_Industrial_m    2025\n",
      "Distance_to_Nearest_Farmland_m      2025\n",
      "Distance_to_Nearest_Landfill_m      2025\n",
      "Distance_to_Nearest_Dump_m          2025\n",
      "latitude                               0\n",
      "longitude                              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ----------------- STEP 5: Merge DataFrames -----------------\n",
    "# Merge air + weather on 'city' (or 'location_id' if available)\n",
    "merged_df = pd.merge(air, weather, on='city', how='left', suffixes=('_air','_weather'))\n",
    "\n",
    "# Merge with features on 'location_id'\n",
    "final_df = pd.merge(merged_df, features, on='location_id', how='left')\n",
    "\n",
    "# Merge with locations to get latitude/longitude\n",
    "final_df = pd.merge(final_df, locations[['location_id','latitude','longitude']], on='location_id', how='left')\n",
    "# Keep latitude/longitude from locations and drop the rest\n",
    "final_df.drop(columns=['latitude_air', 'longitude_air', 'latitude_weather', 'longitude_weather'], inplace=True)\n",
    "\n",
    "# Rename remaining columns for clarity if needed\n",
    "final_df.rename(columns={'latitude':'latitude', 'longitude':'longitude'}, inplace=True)\n",
    "\n",
    "# ----------------- STEP 6: Final Check -----------------\n",
    "print(final_df.shape)\n",
    "print(final_df.head())\n",
    "print(final_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e9b3495-8222-4218-bf40-27a1f6acbe2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Module 2: Data Cleaning & Feature Engineering Complete!\n"
     ]
    }
   ],
   "source": [
    "# ----------------- STEP 7: Save Cleaned Data -----------------\n",
    "final_df.to_csv(r\"D:\\AI-EnviroProject\\processed_data_module2.csv\", index=False)\n",
    "\n",
    "print(\"✅ Module 2: Data Cleaning & Feature Engineering Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d356a5e-ed81-4bec-8d9f-9031aaa80e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Module 3: AQI Classification & ML Data Preparation Complete!\n",
      "Training set: (5640, 24)\n",
      "Test set: (1410, 24)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ----------------- LOAD CLEANED DATA -----------------\n",
    "final_df = pd.read_csv(r\"D:\\AI-EnviroProject\\processed_data_module2.csv\")\n",
    "\n",
    "# ----------------- STEP 1: AQI Classification -----------------\n",
    "# If 'AQI' column exists\n",
    "def classify_aqi(aqi):\n",
    "    if aqi <= 50:\n",
    "        return 'Good'\n",
    "    elif aqi <= 100:\n",
    "        return 'Moderate'\n",
    "    elif aqi <= 200:\n",
    "        return 'Poor'\n",
    "    elif aqi <= 300:\n",
    "        return 'Very Poor'\n",
    "    else:\n",
    "        return 'Hazardous'\n",
    "\n",
    "final_df['AQI_Class'] = final_df['AQI'].apply(classify_aqi)\n",
    "\n",
    "# ----------------- STEP 2: Prepare Features & Target -----------------\n",
    "# Drop non-numeric or target columns from features\n",
    "feature_cols = ['PM25 AQ', 'PM10 AQ', 'CO AQ', 'NO2 AQ', 'SO2 AQ', 'O3 AQ',\n",
    "                'temperature', 'humidity', 'wind_speed', 'wind_deg',\n",
    "                'hour','day_of_week','month','season',\n",
    "                'Road_Count','Industrial_Count','Farmland_Count',\n",
    "                'Landfill_Count','Dump_Site_Count',\n",
    "                'Distance_to_Nearest_Road_m','Distance_to_Nearest_Industrial_m',\n",
    "                'Distance_to_Nearest_Farmland_m','Distance_to_Nearest_Landfill_m',\n",
    "                'Distance_to_Nearest_Dump_m']\n",
    "\n",
    "X = final_df[feature_cols]\n",
    "y = final_df['AQI_Class']\n",
    "\n",
    "# ----------------- STEP 3: Split Train/Test -----------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"✅ Module 3: AQI Classification & ML Data Preparation Complete!\")\n",
    "print(\"Training set:\", X_train.shape)\n",
    "print(\"Test set:\", X_test.shape)\n",
    "\n",
    "# ----------------- STEP 4: Save for Modeling -----------------\n",
    "X_train.to_csv(r\"D:\\AI-EnviroProject\\X_train.csv\", index=False)\n",
    "X_test.to_csv(r\"D:\\AI-EnviroProject\\X_test.csv\", index=False)\n",
    "y_train.to_csv(r\"D:\\AI-EnviroProject\\y_train.csv\", index=False)\n",
    "y_test.to_csv(r\"D:\\AI-EnviroProject\\y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8022846f-2890-4864-9ba4-a2e45f9ac822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pollution Source Counts:\n",
      "Pollution_Source\n",
      "Natural       5168\n",
      "Industrial     890\n",
      "Burning        692\n",
      "Vehicular      300\n",
      "Name: count, dtype: int64\n",
      "✅ Module 3: Pollution Source Labeling Complete!\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Module 3: Source Labeling with Data-Driven Thresholds\n",
    "# =========================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ----------------- LOAD DATA -----------------\n",
    "final_df = pd.read_csv(r\"D:\\AI-EnviroProject\\processed_data_module2.csv\")\n",
    "\n",
    "# ----------------- STEP 1: Derive Season from Timestamp -----------------\n",
    "if 'timestamp' in final_df.columns:\n",
    "    final_df['timestamp'] = pd.to_datetime(final_df['timestamp'])\n",
    "    final_df['month'] = final_df['timestamp'].dt.month\n",
    "    final_df['season'] = final_df['month'].apply(lambda m: 'Winter' if m in [12,1,2]\n",
    "                                                 else 'Spring' if m in [3,4,5]\n",
    "                                                 else 'Summer' if m in [6,7,8]\n",
    "                                                 else 'Autumn')\n",
    "else:\n",
    "    final_df['season'] = 'Summer'\n",
    "\n",
    "# ----------------- STEP 2: Set Data-Driven Thresholds -----------------\n",
    "road_thresh = final_df['Distance_to_Nearest_Road_m'].quantile(0.25)\n",
    "industrial_thresh = final_df['Distance_to_Nearest_Industrial_m'].quantile(0.25)\n",
    "farmland_thresh = final_df['Distance_to_Nearest_Farmland_m'].quantile(0.25)\n",
    "dump_thresh = final_df['Distance_to_Nearest_Dump_m'].quantile(0.25)\n",
    "\n",
    "no2_thresh = final_df['NO2 AQ'].quantile(0.75)\n",
    "so2_thresh = final_df['SO2 AQ'].quantile(0.75)\n",
    "pm25_thresh = final_df['PM25 AQ'].quantile(0.75)\n",
    "pm10_thresh = final_df['PM10 AQ'].quantile(0.75)\n",
    "\n",
    "# ----------------- STEP 3: Define Labeling Function -----------------\n",
    "def label_pollution_source(row):\n",
    "    if row['Distance_to_Nearest_Road_m'] <= road_thresh and row['NO2 AQ'] >= no2_thresh:\n",
    "        return 'Vehicular'\n",
    "    elif row['Distance_to_Nearest_Industrial_m'] <= industrial_thresh and row['SO2 AQ'] >= so2_thresh:\n",
    "        return 'Industrial'\n",
    "    elif row['Distance_to_Nearest_Farmland_m'] <= farmland_thresh and row['PM25 AQ'] >= pm25_thresh and row['season'] in ['Summer','Autumn']:\n",
    "        return 'Agricultural'\n",
    "    elif row['Distance_to_Nearest_Dump_m'] <= dump_thresh and row['PM10 AQ'] >= pm10_thresh:\n",
    "        return 'Burning'\n",
    "    else:\n",
    "        return 'Natural'\n",
    "\n",
    "# ----------------- STEP 4: Apply Labeling -----------------\n",
    "final_df['Pollution_Source'] = final_df.apply(label_pollution_source, axis=1)\n",
    "\n",
    "# ----------------- STEP 5: Check Distribution -----------------\n",
    "print(\"Pollution Source Counts:\")\n",
    "print(final_df['Pollution_Source'].value_counts())\n",
    "\n",
    "# ----------------- STEP 6: Save Labeled Dataset -----------------\n",
    "final_df.to_csv(r\"D:\\AI-EnviroProject\\labeled_dataset.csv\", index=False)\n",
    "print(\"✅ Module 3: Pollution Source Labeling Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f761dee-b97b-4174-936d-af221b8d937b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LabelEncoder Mapping:\n",
      "{'Burning': np.int64(0), 'Industrial': np.int64(1), 'Natural': np.int64(2), 'Vehicular': np.int64(3)}\n",
      "✅ LabelEncoder saved as 'label_encoder.pkl'\n"
     ]
    }
   ],
   "source": [
    "# ----------------- STEP 7: Encode Labels -----------------\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Create LabelEncoder instance\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the Pollution_Source column\n",
    "final_df['Pollution_Source_Encoded'] = le.fit_transform(final_df['Pollution_Source'])\n",
    "\n",
    "# Check mapping\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"✅ LabelEncoder Mapping:\")\n",
    "print(label_mapping)\n",
    "\n",
    "# Optional: Save the LabelEncoder for later use (dashboard or deployment)\n",
    "joblib.dump(le, r\"D:\\AI-EnviroProject\\label_encoder.pkl\")\n",
    "print(\"✅ LabelEncoder saved as 'label_encoder.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41c01fb4-b2e2-46ee-85a6-6d8a941da0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Generated train.csv and app_daily_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load labeled dataset\n",
    "df = pd.read_csv(r\"D:\\AI-EnviroProject\\labeled_dataset.csv\")\n",
    "\n",
    "# Features for ML\n",
    "feature_cols = ['PM25 AQ','PM10 AQ','CO AQ','NO2 AQ','SO2 AQ','O3 AQ',\n",
    "                'temperature','humidity','wind_speed','wind_deg',\n",
    "                'hour','day_of_week','month','season',\n",
    "                'Road_Count','Industrial_Count','Farmland_Count',\n",
    "                'Landfill_Count','Dump_Site_Count',\n",
    "                'Distance_to_Nearest_Road_m','Distance_to_Nearest_Industrial_m',\n",
    "                'Distance_to_Nearest_Farmland_m',\n",
    "                'Distance_to_Nearest_Landfill_m','Distance_to_Nearest_Dump_m']\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['Pollution_Source']\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Save train.csv (for model training)\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "train_df.to_csv(r\"D:\\AI-EnviroProject\\train.csv\", index=False)\n",
    "\n",
    "# Save app_daily_data.csv (all labeled data for dashboard)\n",
    "df.to_csv(r\"D:\\AI-EnviroProject\\app_daily_data.csv\", index=False)\n",
    "\n",
    "print(\"✅ Generated train.csv and app_daily_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3c9786a-aa43-469e-80fb-6401065ee48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9971631205673759\n",
      "Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Burning       1.00      0.99      0.99       138\n",
      "  Industrial       1.00      1.00      1.00       178\n",
      "     Natural       1.00      1.00      1.00      1034\n",
      "   Vehicular       0.95      0.98      0.97        60\n",
      "\n",
      "    accuracy                           1.00      1410\n",
      "   macro avg       0.99      0.99      0.99      1410\n",
      "weighted avg       1.00      1.00      1.00      1410\n",
      "\n",
      "Random Forest Accuracy: 0.9971631205673759\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Burning       0.99      1.00      0.99       138\n",
      "  Industrial       0.99      1.00      1.00       178\n",
      "     Natural       1.00      1.00      1.00      1034\n",
      "   Vehicular       1.00      0.97      0.98        60\n",
      "\n",
      "    accuracy                           1.00      1410\n",
      "   macro avg       0.99      0.99      0.99      1410\n",
      "weighted avg       1.00      1.00      1.00      1410\n",
      "\n",
      "XGBoost Accuracy: 0.997872340425532\n",
      "XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Burning       0.99      1.00      1.00       138\n",
      "  Industrial       0.99      1.00      1.00       178\n",
      "     Natural       1.00      1.00      1.00      1034\n",
      "   Vehicular       1.00      0.98      0.99        60\n",
      "\n",
      "    accuracy                           1.00      1410\n",
      "   macro avg       1.00      1.00      1.00      1410\n",
      "weighted avg       1.00      1.00      1.00      1410\n",
      "\n",
      "Models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- MODULE 4: MODEL TRAINING ----------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Assume final_df is the cleaned, labeled dataset from Module 3\n",
    "# Features: pollutant, weather, proximity\n",
    "feature_cols = [\n",
    "    'PM25 AQ', 'PM10 AQ', 'NO2 AQ', 'SO2 AQ', 'CO AQ', 'O3 AQ',\n",
    "    'temperature', 'humidity', 'wind_speed', 'wind_deg',\n",
    "    'Distance_to_Nearest_Road_m', 'Distance_to_Nearest_Industrial_m',\n",
    "    'Distance_to_Nearest_Farmland_m', 'Distance_to_Nearest_Landfill_m',\n",
    "    'Distance_to_Nearest_Dump_m'\n",
    "]\n",
    "\n",
    "X = final_df[feature_cols]\n",
    "\n",
    "# Encode target\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(final_df['Pollution_Source'])\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# ------------------ DECISION TREE ------------------\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Decision Tree Classification Report:\\n\", classification_report(y_test, y_pred_dt, target_names=le.classes_))\n",
    "\n",
    "# ------------------ RANDOM FOREST ------------------\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, y_pred_rf, target_names=le.classes_))\n",
    "\n",
    "# ------------------ XGBOOST ------------------\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    objective='multi:softmax',   # Multi-class classification\n",
    "    num_class=num_classes,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"XGBoost Classification Report:\\n\", classification_report(y_test, y_pred_xgb, target_names=le.classes_))\n",
    "\n",
    "# ------------------ SAVE MODELS ------------------\n",
    "joblib.dump(dt, r\"D:\\AI-EnviroProject\\decision_tree_model.pkl\")\n",
    "joblib.dump(rf, r\"D:\\AI-EnviroProject\\random_forest_model.pkl\")\n",
    "joblib.dump(xgb, r\"D:\\AI-EnviroProject\\xgboost_model.pkl\")\n",
    "print(\"Models saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e29e381-7c88-41a4-b07c-ca05ba88270b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved successfully!\n",
      "Decision Tree Best Params: {'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "Decision Tree Accuracy: 0.999290780141844\n",
      "Decision Tree Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Burning       1.00      1.00      1.00       138\n",
      "  Industrial       1.00      1.00      1.00       178\n",
      "     Natural       1.00      1.00      1.00      1034\n",
      "   Vehicular       1.00      0.98      0.99        60\n",
      "\n",
      "    accuracy                           1.00      1410\n",
      "   macro avg       1.00      1.00      1.00      1410\n",
      "weighted avg       1.00      1.00      1.00      1410\n",
      "\n",
      "Random Forest Best Params: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Random Forest Accuracy: 0.9971631205673759\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Burning       0.99      1.00      0.99       138\n",
      "  Industrial       0.99      1.00      1.00       178\n",
      "     Natural       1.00      1.00      1.00      1034\n",
      "   Vehicular       1.00      0.97      0.98        60\n",
      "\n",
      "    accuracy                           1.00      1410\n",
      "   macro avg       0.99      0.99      0.99      1410\n",
      "weighted avg       1.00      1.00      1.00      1410\n",
      "\n",
      "XGBoost Best Params: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}\n",
      "XGBoost Accuracy: 0.997872340425532\n",
      "XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Burning       0.99      1.00      0.99       138\n",
      "  Industrial       0.99      1.00      1.00       178\n",
      "     Natural       1.00      1.00      1.00      1034\n",
      "   Vehicular       1.00      1.00      1.00        60\n",
      "\n",
      "    accuracy                           1.00      1410\n",
      "   macro avg       1.00      1.00      1.00      1410\n",
      "weighted avg       1.00      1.00      1.00      1410\n",
      "\n",
      "Best models saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- MODULE 4: MODEL TRAINING WITH GRIDSEARCH & SCALER ----------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# ---------------------- FEATURES & TARGET ----------------------\n",
    "feature_cols = [\n",
    "    'PM25 AQ', 'PM10 AQ', 'NO2 AQ', 'SO2 AQ', 'CO AQ', 'O3 AQ',\n",
    "    'temperature', 'humidity', 'wind_speed', 'wind_deg',\n",
    "    'Distance_to_Nearest_Road_m', 'Distance_to_Nearest_Industrial_m',\n",
    "    'Distance_to_Nearest_Farmland_m', 'Distance_to_Nearest_Landfill_m',\n",
    "    'Distance_to_Nearest_Dump_m'\n",
    "]\n",
    "\n",
    "X = final_df[feature_cols]\n",
    "\n",
    "# Encode target\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(final_df['Pollution_Source'])\n",
    "\n",
    "# ---------------------- SCALE FEATURES ----------------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "joblib.dump(scaler, r\"D:\\AI-EnviroProject\\scaler.joblib\")\n",
    "print(\"Scaler saved successfully!\")\n",
    "\n",
    "# Split scaled dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ---------------------- DECISION TREE WITH GRIDSEARCH ----------------------\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt_params = {\n",
    "    'max_depth': [3, 5, 7, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "dt_grid = GridSearchCV(dt, dt_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "dt_grid.fit(X_train, y_train)\n",
    "best_dt = dt_grid.best_estimator_\n",
    "\n",
    "y_pred_dt = best_dt.predict(X_test)\n",
    "print(\"Decision Tree Best Params:\", dt_grid.best_params_)\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Decision Tree Classification Report:\\n\", classification_report(y_test, y_pred_dt, target_names=le.classes_))\n",
    "\n",
    "# ---------------------- RANDOM FOREST WITH GRIDSEARCH ----------------------\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "rf_grid = GridSearchCV(rf, rf_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "print(\"Random Forest Best Params:\", rf_grid.best_params_)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, y_pred_rf, target_names=le.classes_))\n",
    "\n",
    "# ---------------------- XGBOOST WITH GRIDSEARCH ----------------------\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=num_classes,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.7, 1.0],\n",
    "    'colsample_bytree': [0.7, 1.0]\n",
    "}\n",
    "xgb_grid = GridSearchCV(xgb, xgb_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "best_xgb = xgb_grid.best_estimator_\n",
    "\n",
    "y_pred_xgb = best_xgb.predict(X_test)\n",
    "print(\"XGBoost Best Params:\", xgb_grid.best_params_)\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"XGBoost Classification Report:\\n\", classification_report(y_test, y_pred_xgb, target_names=le.classes_))\n",
    "\n",
    "# ---------------------- SAVE BEST MODELS ----------------------\n",
    "joblib.dump(best_dt, r\"D:\\AI-EnviroProject\\best_decision_tree_model.pkl\")\n",
    "joblib.dump(best_rf, r\"D:\\AI-EnviroProject\\best_random_forest_model.pkl\")\n",
    "joblib.dump(best_xgb, r\"D:\\AI-EnviroProject\\best_xgboost_model.pkl\")\n",
    "print(\"Best models saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "02119fa5-c032-4024-bef9-ba056f578906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: pollution_heatmap.html\n",
      "Saved: pollution_sources_map.html\n",
      "Saved: high_risk_zones.html\n",
      "Saved: high_aqi_locations.html\n",
      "✅ All four main maps saved successfully in 'all_html_file' folder!\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- Module 5: Geospatial Mapping and Heatmap Visualization   ----------------------\n",
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import HeatMap, MarkerCluster\n",
    "import os\n",
    "\n",
    "# ------------------ LOAD DATA ------------------\n",
    "final_df = pd.read_csv(r\"D:\\AI-EnviroProject\\labeled_dataset.csv\")\n",
    "# Columns: latitude, longitude, AQI, Pollution_Source, city_x, timestamp\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "final_df['timestamp'] = pd.to_datetime(final_df['timestamp'])\n",
    "\n",
    "# ------------------ BASE SETTINGS ------------------\n",
    "india_center = [20.5937, 78.9629]\n",
    "zoom_start = 5\n",
    "save_path = r\"D:\\AI-EnviroProject\\all_html_file\"  # folder from your screenshot\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# ------------------ SOURCE ICONS & COLORS ------------------\n",
    "source_icons = {\n",
    "    'Vehicular': 'car',\n",
    "    'Industrial': 'industry',\n",
    "    'Agricultural': 'leaf',\n",
    "    'Burning': 'fire',\n",
    "    'Natural': 'tree'\n",
    "}\n",
    "\n",
    "source_colors = {\n",
    "    'Vehicular': 'blue',\n",
    "    'Industrial': 'red',\n",
    "    'Agricultural': 'green',\n",
    "    'Burning': 'orange',\n",
    "    'Natural': 'gray'\n",
    "}\n",
    "\n",
    "# ------------------ FUNCTION TO CREATE MAP ------------------\n",
    "def create_map(df, file_name, heatmap=False):\n",
    "    m = folium.Map(location=india_center, zoom_start=zoom_start)\n",
    "    \n",
    "    if heatmap:\n",
    "        heat_data = [[row['latitude'], row['longitude'], row['AQI']] for idx, row in df.iterrows()]\n",
    "        HeatMap(heat_data, radius=15, max_zoom=13).add_to(m)\n",
    "    \n",
    "    marker_cluster = MarkerCluster().add_to(m)\n",
    "    for idx, row in df.iterrows():\n",
    "        folium.Marker(\n",
    "            location=[row['latitude'], row['longitude']],\n",
    "            popup=(f\"City: {row['city_x']}<br>\"\n",
    "                   f\"Timestamp: {row['timestamp']}<br>\"\n",
    "                   f\"Source: {row['Pollution_Source']}<br>\"\n",
    "                   f\"AQI: {row['AQI']}\"),\n",
    "            icon=folium.Icon(color=source_colors.get(row['Pollution_Source'], 'black'),\n",
    "                             icon=source_icons.get(row['Pollution_Source'], 'info-sign'),\n",
    "                             prefix='fa')\n",
    "        ).add_to(marker_cluster)\n",
    "    \n",
    "    m.save(os.path.join(save_path, file_name))\n",
    "    print(f\"Saved: {file_name}\")\n",
    "\n",
    "# ------------------ SAVE MAIN MAPS ------------------\n",
    "\n",
    "# 1. Overall heatmap\n",
    "create_map(final_df, \"pollution_heatmap.html\", heatmap=True)\n",
    "\n",
    "# 2. All pollution sources map\n",
    "create_map(final_df, \"pollution_sources_map.html\", heatmap=False)\n",
    "\n",
    "# 3. High-risk zones (AQI > 150)\n",
    "high_risk_df = final_df[final_df['AQI'] > 150]\n",
    "create_map(high_risk_df, \"high_risk_zones.html\", heatmap=True)\n",
    "\n",
    "# 4. High AQI locations (AQI > 200)\n",
    "high_aqi_df = final_df[final_df['AQI'] > 200]\n",
    "create_map(high_aqi_df, \"high_aqi_locations.html\", heatmap=True)\n",
    "\n",
    "print(\"✅ All four main maps saved successfully in 'all_html_file' folder!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae3525c3-9f17-4cd8-a21d-72801f30e50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['city_x', 'PM25 AQ', 'PM25 AQI Category', 'PM10 AQ',\n",
       "       'PM10 AQI Category', 'CO AQ', 'CO AQI Category', 'NO2 AQ',\n",
       "       'NO2 AQI Category', 'SO2 AQ', 'SO2 AQI Category', 'O3 AQ',\n",
       "       'O3 AQI Category', 'AQI', 'location_id', 'temperature', 'humidity',\n",
       "       'wind_speed', 'wind_deg', 'timestamp', 'hour', 'day_of_week', 'month',\n",
       "       'season', 'city_y', 'Road_Count', 'Industrial_Count', 'Farmland_Count',\n",
       "       'Landfill_Count', 'Dump_Site_Count', 'Distance_to_Nearest_Road_m',\n",
       "       'Distance_to_Nearest_Industrial_m', 'Distance_to_Nearest_Farmland_m',\n",
       "       'Distance_to_Nearest_Landfill_m', 'Distance_to_Nearest_Dump_m',\n",
       "       'latitude', 'longitude', 'Pollution_Source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eae4486-10cd-4db9-a862-ea102089f31a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
