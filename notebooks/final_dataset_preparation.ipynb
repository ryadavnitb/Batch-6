{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b014fb",
   "metadata": {},
   "source": [
    "## Cell 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f2792cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae48dfd",
   "metadata": {},
   "source": [
    "## Cell 2: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e24982cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded: 106,369 records, 84 columns\n",
      "\n",
      "âš ï¸ Columns with missing values:\n",
      "   power_plants_distance_m: 87,217 (82.0%)\n",
      "   agricultural_distance_m: 72,965 (68.6%)\n",
      "   dump_sites_distance_m: 65,727 (61.8%)\n",
      "   commercial_distance_m: 47,099 (44.3%)\n",
      "   industrial_distance_m: 30,196 (28.4%)\n",
      "   residential_distance_m: 17,496 (16.4%)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/cleaned/india_aq_cleaned_features.csv')\n",
    "print(f\"âœ… Loaded: {len(df):,} records, {len(df.columns)} columns\")\n",
    "\n",
    "# Check missing values\n",
    "missing = df.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "print(f\"\\nâš ï¸ Columns with missing values:\")\n",
    "for col, count in missing.items():\n",
    "    print(f\"   {col}: {count:,} ({count/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cf78ad",
   "metadata": {},
   "source": [
    "## Cell 3: Handle Missing Values\n",
    "**Strategy:**\n",
    "- Distance columns (NaN = no feature found nearby) â†’ Fill with large value (9999m)\n",
    "- Area/Count columns (NaN = no feature) â†’ Fill with 0\n",
    "- Weather outliers â†’ Clip to realistic ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc0a7131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Filled 7 distance columns with 9999m (far away)\n",
      "âœ… Filled 13 area/count columns with 0\n",
      "\n",
      "âœ… Remaining missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Distance columns: NaN means no feature found â†’ use large distance\n",
    "distance_cols = [c for c in df.columns if '_distance_m' in c]\n",
    "for col in distance_cols:\n",
    "    df[col] = df[col].fillna(9999)\n",
    "print(f\"âœ… Filled {len(distance_cols)} distance columns with 9999m (far away)\")\n",
    "\n",
    "# Area/Count columns: NaN means no feature â†’ use 0\n",
    "area_cols = [c for c in df.columns if '_area_sqm' in c or '_count' in c]\n",
    "for col in area_cols:\n",
    "    df[col] = df[col].fillna(0)\n",
    "print(f\"âœ… Filled {len(area_cols)} area/count columns with 0\")\n",
    "\n",
    "# Verify no missing values\n",
    "remaining = df.isnull().sum().sum()\n",
    "print(f\"\\nâœ… Remaining missing values: {remaining}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c7c10",
   "metadata": {},
   "source": [
    "## Cell 4: Handle Weather Outliers\n",
    "Clip unrealistic weather values to valid ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a20ce873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Temperature: Clipped 265 outliers to [-10, 50]Â°C\n",
      "âœ… Humidity: Clipped 1,500 outliers to [0, 100]%\n",
      "âœ… Wind speed: Clipped 2,072 outliers to [0, 50] m/s\n",
      "âœ… Pollutants: Clipped 639 extreme values (>99.9 percentile)\n"
     ]
    }
   ],
   "source": [
    "# Temperature: -10Â°C to 50Â°C (realistic for India)\n",
    "before_temp = len(df[(df['temperature'] < -10) | (df['temperature'] > 50)])\n",
    "df['temperature'] = df['temperature'].clip(-10, 50)\n",
    "print(f\"âœ… Temperature: Clipped {before_temp:,} outliers to [-10, 50]Â°C\")\n",
    "\n",
    "# Humidity: 0% to 100%\n",
    "before_hum = len(df[(df['humidity'] < 0) | (df['humidity'] > 100)])\n",
    "df['humidity'] = df['humidity'].clip(0, 100)\n",
    "print(f\"âœ… Humidity: Clipped {before_hum:,} outliers to [0, 100]%\")\n",
    "\n",
    "# Wind speed: 0 to 50 m/s\n",
    "before_wind = len(df[(df['wind_speed'] < 0) | (df['wind_speed'] > 50)])\n",
    "df['wind_speed'] = df['wind_speed'].clip(0, 50)\n",
    "print(f\"âœ… Wind speed: Clipped {before_wind:,} outliers to [0, 50] m/s\")\n",
    "\n",
    "# Pollutants: Remove extreme outliers (>99.9 percentile)\n",
    "pollutants = ['pm25', 'pm10', 'no2', 'co', 'so2', 'o3']\n",
    "total_clipped = 0\n",
    "for pol in pollutants:\n",
    "    upper = df[pol].quantile(0.999)\n",
    "    clipped = (df[pol] > upper).sum()\n",
    "    df[pol] = df[pol].clip(0, upper)\n",
    "    total_clipped += clipped\n",
    "print(f\"âœ… Pollutants: Clipped {total_clipped:,} extreme values (>99.9 percentile)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d60292c",
   "metadata": {},
   "source": [
    "## Cell 5: Select Essential Columns\n",
    "Keep only columns needed for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e2c5ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Selected 30 essential columns\n",
      "\n",
      "Columns: ['state', 'district', 'location_id', 'location_name', 'latitude', 'longitude', 'datetime_ist', 'hour', 'day_of_week', 'month', 'season', 'is_weekend', 'is_rush_hour', 'pm25', 'pm10', 'no2', 'co', 'so2', 'o3', 'temperature', 'humidity', 'wind_speed', 'roads_distance_m', 'roads_count', 'industrial_distance_m', 'industrial_area_sqm', 'agricultural_distance_m', 'agricultural_area_sqm', 'dump_sites_distance_m', 'dump_sites_count']\n"
     ]
    }
   ],
   "source": [
    "essential_cols = [\n",
    "    # Location\n",
    "    'state', 'district', 'location_id', 'location_name', 'latitude', 'longitude',\n",
    "    # Time\n",
    "    'datetime_ist', 'hour', 'day_of_week', 'month', 'season', 'is_weekend', 'is_rush_hour',\n",
    "    # Pollutants\n",
    "    'pm25', 'pm10', 'no2', 'co', 'so2', 'o3',\n",
    "    # Weather\n",
    "    'temperature', 'humidity', 'wind_speed',\n",
    "    # Spatial (roads)\n",
    "    'roads_distance_m', 'roads_count',\n",
    "    # Spatial (industrial)\n",
    "    'industrial_distance_m', 'industrial_area_sqm',\n",
    "    # Spatial (agricultural)\n",
    "    'agricultural_distance_m', 'agricultural_area_sqm',\n",
    "    # Spatial (dump sites)\n",
    "    'dump_sites_distance_m', 'dump_sites_count',\n",
    "]\n",
    "\n",
    "cols = [c for c in essential_cols if c in df.columns]\n",
    "df_clean = df[cols].copy()\n",
    "\n",
    "print(f\"âœ… Selected {len(df_clean.columns)} essential columns\")\n",
    "print(f\"\\nColumns: {list(df_clean.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce119e4",
   "metadata": {},
   "source": [
    "## Cell 6: Calculate Thresholds\n",
    "Use percentile-based thresholds for pollutant levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5337044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Thresholds:\n",
      "   pm25: low=29.7, med=51.8, high=77.3, v.high=109.4\n",
      "   pm10: low=63.0, med=101.7, high=147.5, v.high=206.0\n",
      "   no2: low=5.9, med=14.3, high=25.4, v.high=47.9\n",
      "   co: low=0.4, med=0.7, high=1.0, v.high=1.6\n",
      "   so2: low=5.1, med=10.2, high=17.4, v.high=30.7\n",
      "   o3: low=9.3, med=21.9, high=37.7, v.high=63.0\n"
     ]
    }
   ],
   "source": [
    "thresholds = {}\n",
    "for col in ['pm25', 'pm10', 'no2', 'co', 'so2', 'o3']:\n",
    "    thresholds[col] = {\n",
    "        'low': df_clean[col].quantile(0.25),\n",
    "        'medium': df_clean[col].quantile(0.50),\n",
    "        'high': df_clean[col].quantile(0.75),\n",
    "        'very_high': df_clean[col].quantile(0.90)\n",
    "    }\n",
    "\n",
    "print(\"âœ… Thresholds:\")\n",
    "for pol, vals in thresholds.items():\n",
    "    print(f\"   {pol}: low={vals['low']:.1f}, med={vals['medium']:.1f}, high={vals['high']:.1f}, v.high={vals['very_high']:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b835ff5a",
   "metadata": {},
   "source": [
    "## Cell 7: Define Scoring Functions\n",
    "Each source has a scoring function based on:\n",
    "- Spatial proximity\n",
    "- Pollutant levels\n",
    "- Temporal patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "776e4551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scoring functions defined!\n"
     ]
    }
   ],
   "source": [
    "def score_vehicular(row, th):\n",
    "    \"\"\"Vehicular: Roads + NO2 + Rush hour\"\"\"\n",
    "    score = 0\n",
    "    dist = row.get('roads_distance_m', 9999)\n",
    "    if dist <= 50: score += 5\n",
    "    elif dist <= 100: score += 4\n",
    "    elif dist <= 200: score += 3\n",
    "    elif dist <= 500: score += 2\n",
    "    \n",
    "    if row.get('roads_count', 0) > 200: score += 3\n",
    "    elif row.get('roads_count', 0) > 100: score += 2\n",
    "    \n",
    "    no2 = row.get('no2', 0)\n",
    "    if no2 > th['no2']['very_high']: score += 5\n",
    "    elif no2 > th['no2']['high']: score += 3\n",
    "    \n",
    "    if row.get('is_rush_hour', 0) == 1: score += 2\n",
    "    return score\n",
    "\n",
    "def score_industrial(row, th):\n",
    "    \"\"\"Industrial: Factories + SO2 + Industrial area\"\"\"\n",
    "    score = 0\n",
    "    dist = row.get('industrial_distance_m', 9999)\n",
    "    if dist <= 500: score += 4\n",
    "    elif dist <= 1000: score += 3\n",
    "    elif dist <= 2000: score += 2\n",
    "    \n",
    "    area = row.get('industrial_area_sqm', 0)\n",
    "    if area > 5000000: score += 5\n",
    "    elif area > 1000000: score += 4\n",
    "    elif area > 100000: score += 2\n",
    "    \n",
    "    so2 = row.get('so2', 0)\n",
    "    if so2 > th['so2']['very_high']: score += 5\n",
    "    elif so2 > th['so2']['high']: score += 3\n",
    "    \n",
    "    if row.get('is_weekend', 1) == 0: score += 1\n",
    "    return score\n",
    "\n",
    "def score_agricultural(row, th):\n",
    "    \"\"\"Agricultural: Farmland + PM + Dry season\"\"\"\n",
    "    score = 0\n",
    "    dist = row.get('agricultural_distance_m', 9999)\n",
    "    if dist <= 500: score += 4\n",
    "    elif dist <= 1000: score += 3\n",
    "    \n",
    "    area = row.get('agricultural_area_sqm', 0)\n",
    "    if area > 100000: score += 4\n",
    "    elif area > 50000: score += 2\n",
    "    \n",
    "    if row.get('pm10', 0) > th['pm10']['high']: score += 3\n",
    "    if row.get('pm25', 0) > th['pm25']['high']: score += 2\n",
    "    \n",
    "    if row.get('season', '') in ['post_monsoon', 'winter']: score += 3\n",
    "    return score\n",
    "\n",
    "def score_burning(row, th):\n",
    "    \"\"\"Burning: Dump sites + CO + Evening\"\"\"\n",
    "    score = 0\n",
    "    dist = row.get('dump_sites_distance_m', 9999)\n",
    "    if dist <= 300: score += 5\n",
    "    elif dist <= 500: score += 4\n",
    "    elif dist <= 1000: score += 3\n",
    "    \n",
    "    if row.get('dump_sites_count', 0) > 0: score += 2\n",
    "    \n",
    "    co = row.get('co', 0)\n",
    "    if co > th['co']['very_high']: score += 4\n",
    "    elif co > th['co']['high']: score += 2\n",
    "    \n",
    "    hour = row.get('hour', 12)\n",
    "    if 18 <= hour <= 23 or 0 <= hour <= 5: score += 2\n",
    "    return score\n",
    "\n",
    "def score_natural(row, th):\n",
    "    \"\"\"Natural: High PM ratio + Low gases + Wind\"\"\"\n",
    "    score = 0\n",
    "    pm25 = row.get('pm25', 1)\n",
    "    pm10 = row.get('pm10', 0)\n",
    "    \n",
    "    if pm25 > 0:\n",
    "        ratio = pm10 / pm25\n",
    "        if ratio > 3: score += 5\n",
    "        elif ratio > 2: score += 3\n",
    "    \n",
    "    if row.get('no2', 999) < th['no2']['medium']: score += 2\n",
    "    if row.get('so2', 999) < th['so2']['medium']: score += 2\n",
    "    if row.get('co', 999) < th['co']['medium']: score += 2\n",
    "    \n",
    "    if row.get('wind_speed', 0) > 5: score += 3\n",
    "    return score\n",
    "\n",
    "print(\"âœ… Scoring functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e506e630",
   "metadata": {},
   "source": [
    "## Cell 8: Apply Labels\n",
    "Assign pollution source based on highest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0426a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Labeling... (1-2 min)\n",
      "\n",
      "âœ… Label Distribution:\n",
      "   Vehicular      : 42,445 ( 39.9%)\n",
      "   Industrial     : 23,372 ( 22.0%)\n",
      "   Agricultural   : 21,389 ( 20.1%)\n",
      "   Natural        : 12,061 ( 11.3%)\n",
      "   Burning        :  7,102 (  6.7%)\n"
     ]
    }
   ],
   "source": [
    "def assign_label(row, th):\n",
    "    scores = {\n",
    "        'Vehicular': score_vehicular(row, th),\n",
    "        'Industrial': score_industrial(row, th),\n",
    "        'Agricultural': score_agricultural(row, th),\n",
    "        'Burning': score_burning(row, th),\n",
    "        'Natural': score_natural(row, th)\n",
    "    }\n",
    "    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_source, top_score = sorted_scores[0]\n",
    "    margin = top_score - sorted_scores[1][1]\n",
    "    \n",
    "    if margin >= 5: confidence = 'High'\n",
    "    elif margin >= 3: confidence = 'Medium'\n",
    "    else: confidence = 'Low'\n",
    "    \n",
    "    return top_source, confidence, top_score\n",
    "\n",
    "print(\"â³ Labeling... (1-2 min)\")\n",
    "results = [assign_label(row, thresholds) for _, row in df_clean.iterrows()]\n",
    "\n",
    "df_clean['pollution_source'] = [r[0] for r in results]\n",
    "df_clean['confidence'] = [r[1] for r in results]\n",
    "df_clean['score'] = [r[2] for r in results]\n",
    "\n",
    "print(\"\\nâœ… Label Distribution:\")\n",
    "for label, count in df_clean['pollution_source'].value_counts().items():\n",
    "    print(f\"   {label:15}: {count:>6,} ({count/len(df_clean)*100:>5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a110f21a",
   "metadata": {},
   "source": [
    "## Cell 9: Validate Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3610719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Average Pollutants by Source:\n",
      "                    no2    so2    co   pm25    pm10\n",
      "pollution_source                                   \n",
      "Agricultural      11.01  12.37  0.68  51.65  105.23\n",
      "Burning           12.11   7.58  1.11  61.53   94.80\n",
      "Industrial        23.43  22.26  0.94  71.54  120.17\n",
      "Natural           10.04   6.12  0.42  29.68   79.65\n",
      "Vehicular         29.05  14.42  0.79  67.93  131.30\n",
      "\n",
      "ðŸ“Š Confidence Distribution:\n",
      "   Low     : 60,050 ( 56.5%)\n",
      "   Medium  : 26,418 ( 24.8%)\n",
      "   High    : 19,901 ( 18.7%)\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ“Š Average Pollutants by Source:\")\n",
    "print(df_clean.groupby('pollution_source')[['no2', 'so2', 'co', 'pm25', 'pm10']].mean().round(2))\n",
    "\n",
    "print(\"\\nðŸ“Š Confidence Distribution:\")\n",
    "for conf, count in df_clean['confidence'].value_counts().items():\n",
    "    print(f\"   {conf:8}: {count:>6,} ({count/len(df_clean)*100:>5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe354be5",
   "metadata": {},
   "source": [
    "## Cell 10: Create Encoded Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a85265a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Label Encoding:\n",
      "   0 = Vehicular       (42,445)\n",
      "   1 = Industrial      (23,372)\n",
      "   2 = Agricultural    (21,389)\n",
      "   3 = Burning         (7,102)\n",
      "   4 = Natural         (12,061)\n"
     ]
    }
   ],
   "source": [
    "label_map = {'Vehicular': 0, 'Industrial': 1, 'Agricultural': 2, 'Burning': 3, 'Natural': 4}\n",
    "df_clean['source_encoded'] = df_clean['pollution_source'].map(label_map)\n",
    "\n",
    "print(\"âœ… Label Encoding:\")\n",
    "for label, code in label_map.items():\n",
    "    count = (df_clean['pollution_source'] == label).sum()\n",
    "    print(f\"   {code} = {label:15} ({count:,})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdd6551",
   "metadata": {},
   "source": [
    "## Cell 11: Final Dataset Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28c3e11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š FINAL DATASET SUMMARY\n",
      "==================================================\n",
      "Total Records: 106,369\n",
      "Total Columns: 33\n",
      "States: 19\n",
      "Districts: 49\n",
      "Locations: 49\n",
      "Missing Values: 0\n",
      "\n",
      "Data Types:\n",
      "float64    17\n",
      "int64       9\n",
      "object      7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "final_cols = [\n",
    "    'state', 'district', 'location_id', 'location_name', 'latitude', 'longitude',\n",
    "    'datetime_ist', 'hour', 'day_of_week', 'month', 'season', 'is_weekend', 'is_rush_hour',\n",
    "    'pm25', 'pm10', 'no2', 'co', 'so2', 'o3',\n",
    "    'temperature', 'humidity', 'wind_speed',\n",
    "    'roads_distance_m', 'roads_count',\n",
    "    'industrial_distance_m', 'industrial_area_sqm',\n",
    "    'agricultural_distance_m', 'agricultural_area_sqm',\n",
    "    'dump_sites_distance_m', 'dump_sites_count',\n",
    "    'pollution_source', 'source_encoded', 'confidence'\n",
    "]\n",
    "\n",
    "df_final = df_clean[[c for c in final_cols if c in df_clean.columns]].copy()\n",
    "\n",
    "print(\"ðŸ“Š FINAL DATASET SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total Records: {len(df_final):,}\")\n",
    "print(f\"Total Columns: {len(df_final.columns)}\")\n",
    "print(f\"States: {df_final['state'].nunique()}\")\n",
    "print(f\"Districts: {df_final['district'].nunique()}\")\n",
    "print(f\"Locations: {df_final['location_id'].nunique()}\")\n",
    "print(f\"Missing Values: {df_final.isnull().sum().sum()}\")\n",
    "print(f\"\\nData Types:\")\n",
    "print(df_final.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03bce73",
   "metadata": {},
   "source": [
    "## Cell 12: Save Final Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bf24b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: data/final/enviroscan_final_dataset.csv (106,369 records)\n",
      "âœ… Saved: data/final/enviroscan_training_set.csv (46,319 records)\n",
      "âœ… Saved: data/final/label_summary.csv\n",
      "\n",
      "==================================================\n",
      "ðŸŽ‰ DATASET PREPARATION COMPLETE!\n",
      "==================================================\n",
      "\n",
      "Full Dataset: 106,369 records\n",
      "Training Set: 46,319 records (43.5%)\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('data/final', exist_ok=True)\n",
    "\n",
    "# Full dataset\n",
    "df_final.to_csv('data/final/enviroscan_final_dataset.csv', index=False)\n",
    "print(f\"âœ… Saved: data/final/enviroscan_final_dataset.csv ({len(df_final):,} records)\")\n",
    "\n",
    "# Training set (High + Medium confidence)\n",
    "df_train = df_final[df_final['confidence'].isin(['High', 'Medium'])].copy()\n",
    "df_train.to_csv('data/final/enviroscan_training_set.csv', index=False)\n",
    "print(f\"âœ… Saved: data/final/enviroscan_training_set.csv ({len(df_train):,} records)\")\n",
    "\n",
    "# Label summary\n",
    "summary = df_final.groupby(['pollution_source', 'confidence']).size().reset_index(name='count')\n",
    "summary.to_csv('data/final/label_summary.csv', index=False)\n",
    "print(f\"âœ… Saved: data/final/label_summary.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸŽ‰ DATASET PREPARATION COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nFull Dataset: {len(df_final):,} records\")\n",
    "print(f\"Training Set: {len(df_train):,} records ({len(df_train)/len(df_final)*100:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
