{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "317a42f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAQ modules cleaned from cache\n",
      "API Key configured: eccdc2f296...\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Configuration\n",
    "# OpenAQ API Key\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Load environment variables from .env file if present\n",
    "OPENAQ_API_KEY = os.getenv(\"OPENAQ_API_KEY\")    \n",
    "\n",
    "# Force complete reimport of openaq module\n",
    "import sys\n",
    "modules_to_remove = [key for key in sys.modules.keys() if key.startswith('openaq')]\n",
    "for mod in modules_to_remove:\n",
    "    del sys.modules[mod]\n",
    "\n",
    "print(\"OpenAQ modules cleaned from cache\")\n",
    "print(f\"API Key configured: {OPENAQ_API_KEY[:10]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bb3fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define India States and Major Districts with Coordinates\n",
    "\n",
    "# Dictionary of Indian states with 5 major districts each\n",
    "# Format: {state_name: [(district_name, latitude, longitude), ...]}\n",
    "\n",
    "INDIA_STATES_DISTRICTS = {\n",
    "    \"Andhra Pradesh\": [\n",
    "        (\"Visakhapatnam\", 17.6868, 83.2185),\n",
    "        (\"Vijayawada\", 16.5062, 80.6480),\n",
    "        (\"Guntur\", 16.3067, 80.4365),\n",
    "        (\"Tirupati\", 13.6288, 79.4192),\n",
    "        (\"Nellore\", 14.4426, 79.9865),\n",
    "    ],\n",
    "    \"Arunachal Pradesh\": [\n",
    "        (\"Itanagar\", 27.0844, 93.6053),\n",
    "        (\"Naharlagun\", 27.1044, 93.6945),\n",
    "        (\"Pasighat\", 28.0670, 95.3269),\n",
    "        (\"Tawang\", 27.5861, 91.8594),\n",
    "        (\"Ziro\", 27.5450, 93.8260),\n",
    "    ],\n",
    "    \"Assam\": [\n",
    "        (\"Guwahati\", 26.1445, 91.7362),\n",
    "        (\"Silchar\", 24.8333, 92.7789),\n",
    "        (\"Dibrugarh\", 27.4728, 94.9120),\n",
    "        (\"Jorhat\", 26.7509, 94.2037),\n",
    "        (\"Tezpur\", 26.6528, 92.7926),\n",
    "    ],\n",
    "    \"Bihar\": [\n",
    "        (\"Patna\", 25.5941, 85.1376),\n",
    "        (\"Gaya\", 24.7914, 85.0002),\n",
    "        (\"Muzaffarpur\", 26.1209, 85.3647),\n",
    "        (\"Bhagalpur\", 25.2425, 86.9842),\n",
    "        (\"Darbhanga\", 26.1542, 85.8918),\n",
    "    ],\n",
    "    \"Chhattisgarh\": [\n",
    "        (\"Raipur\", 21.2514, 81.6296),\n",
    "        (\"Bhilai\", 21.2094, 81.3509),\n",
    "        (\"Bilaspur\", 22.0796, 82.1391),\n",
    "        (\"Korba\", 22.3595, 82.7501),\n",
    "        (\"Durg\", 21.1904, 81.2849),\n",
    "    ],\n",
    "    \"Goa\": [\n",
    "        (\"Panaji\", 15.4909, 73.8278),\n",
    "        (\"Margao\", 15.2832, 73.9862),\n",
    "        (\"Vasco da Gama\", 15.3959, 73.8154),\n",
    "        (\"Mapusa\", 15.5916, 73.8127),\n",
    "        (\"Ponda\", 15.4034, 74.0152),\n",
    "    ],\n",
    "    \"Gujarat\": [\n",
    "        (\"Ahmedabad\", 23.0225, 72.5714),\n",
    "        (\"Surat\", 21.1702, 72.8311),\n",
    "        (\"Vadodara\", 22.3072, 73.1812),\n",
    "        (\"Rajkot\", 22.3039, 70.8022),\n",
    "        (\"Gandhinagar\", 23.2156, 72.6369),\n",
    "    ],\n",
    "    \"Haryana\": [\n",
    "        (\"Gurugram\", 28.4595, 77.0266),\n",
    "        (\"Faridabad\", 28.4089, 77.3178),\n",
    "        (\"Panipat\", 29.3909, 76.9635),\n",
    "        (\"Ambala\", 30.3782, 76.7767),\n",
    "        (\"Hisar\", 29.1492, 75.7217),\n",
    "    ],\n",
    "    \"Himachal Pradesh\": [\n",
    "        (\"Shimla\", 31.1048, 77.1734),\n",
    "        (\"Dharamshala\", 32.2190, 76.3234),\n",
    "        (\"Manali\", 32.2396, 77.1887),\n",
    "        (\"Kullu\", 31.9592, 77.1089),\n",
    "        (\"Solan\", 30.9045, 77.0967),\n",
    "    ],\n",
    "    \"Jharkhand\": [\n",
    "        (\"Ranchi\", 23.3441, 85.3096),\n",
    "        (\"Jamshedpur\", 22.8046, 86.2029),\n",
    "        (\"Dhanbad\", 23.7957, 86.4304),\n",
    "        (\"Bokaro\", 23.6693, 86.1511),\n",
    "        (\"Hazaribagh\", 23.9925, 85.3637),\n",
    "    ],\n",
    "    \"Karnataka\": [\n",
    "        (\"Bengaluru\", 12.9716, 77.5946),\n",
    "        (\"Mysuru\", 12.2958, 76.6394),\n",
    "        (\"Hubli\", 15.3647, 75.1240),\n",
    "        (\"Mangaluru\", 12.9141, 74.8560),\n",
    "        (\"Belgaum\", 15.8497, 74.4977),\n",
    "    ],\n",
    "    \"Kerala\": [\n",
    "        (\"Thiruvananthapuram\", 8.5241, 76.9366),\n",
    "        (\"Kochi\", 9.9312, 76.2673),\n",
    "        (\"Kozhikode\", 11.2588, 75.7804),\n",
    "        (\"Thrissur\", 10.5276, 76.2144),\n",
    "        (\"Kannur\", 11.8745, 75.3704),\n",
    "    ],\n",
    "    \"Madhya Pradesh\": [\n",
    "        (\"Bhopal\", 23.2599, 77.4126),\n",
    "        (\"Indore\", 22.7196, 75.8577),\n",
    "        (\"Jabalpur\", 23.1815, 79.9864),\n",
    "        (\"Gwalior\", 26.2183, 78.1828),\n",
    "        (\"Ujjain\", 23.1765, 75.7885),\n",
    "    ],\n",
    "    \"Maharashtra\": [\n",
    "        (\"Mumbai\", 19.0760, 72.8777),\n",
    "        (\"Pune\", 18.5204, 73.8567),\n",
    "        (\"Nagpur\", 21.1458, 79.0882),\n",
    "        (\"Nashik\", 19.9975, 73.7898),\n",
    "        (\"Aurangabad\", 19.8762, 75.3433),\n",
    "    ],\n",
    "    \"Manipur\": [\n",
    "        (\"Imphal\", 24.8170, 93.9368),\n",
    "        (\"Thoubal\", 24.6342, 94.0132),\n",
    "        (\"Bishnupur\", 24.6270, 93.7610),\n",
    "        (\"Churachandpur\", 24.3333, 93.6833),\n",
    "        (\"Ukhrul\", 25.0492, 94.3616),\n",
    "    ],\n",
    "    \"Meghalaya\": [\n",
    "        (\"Shillong\", 25.5788, 91.8933),\n",
    "        (\"Tura\", 25.5144, 90.2003),\n",
    "        (\"Jowai\", 25.4529, 92.2035),\n",
    "        (\"Nongpoh\", 25.9042, 91.8806),\n",
    "        (\"Williamnagar\", 25.4939, 90.6178),\n",
    "    ],\n",
    "    \"Mizoram\": [\n",
    "        (\"Aizawl\", 23.7271, 92.7176),\n",
    "        (\"Lunglei\", 22.8839, 92.7322),\n",
    "        (\"Champhai\", 23.4567, 93.3281),\n",
    "        (\"Serchhip\", 23.3067, 92.8506),\n",
    "        (\"Kolasib\", 24.2239, 92.6789),\n",
    "    ],\n",
    "    \"Nagaland\": [\n",
    "        (\"Kohima\", 25.6751, 94.1086),\n",
    "        (\"Dimapur\", 25.9064, 93.7273),\n",
    "        (\"Mokokchung\", 26.3167, 94.5167),\n",
    "        (\"Tuensang\", 26.2667, 94.8333),\n",
    "        (\"Wokha\", 26.1000, 94.2667),\n",
    "    ],\n",
    "    \"Odisha\": [\n",
    "        (\"Bhubaneswar\", 20.2961, 85.8245),\n",
    "        (\"Cuttack\", 20.4625, 85.8830),\n",
    "        (\"Rourkela\", 22.2604, 84.8536),\n",
    "        (\"Puri\", 19.8135, 85.8312),\n",
    "        (\"Sambalpur\", 21.4669, 83.9756),\n",
    "    ],\n",
    "    \"Punjab\": [\n",
    "        (\"Ludhiana\", 30.9010, 75.8573),\n",
    "        (\"Amritsar\", 31.6340, 74.8723),\n",
    "        (\"Jalandhar\", 31.3260, 75.5762),\n",
    "        (\"Patiala\", 30.3398, 76.3869),\n",
    "        (\"Bathinda\", 30.2110, 74.9455),\n",
    "    ],\n",
    "    \"Rajasthan\": [\n",
    "        (\"Jaipur\", 26.9124, 75.7873),\n",
    "        (\"Jodhpur\", 26.2389, 73.0243),\n",
    "        (\"Udaipur\", 24.5854, 73.7125),\n",
    "        (\"Kota\", 25.2138, 75.8648),\n",
    "        (\"Ajmer\", 26.4499, 74.6399),\n",
    "    ],\n",
    "    \"Sikkim\": [\n",
    "        (\"Gangtok\", 27.3389, 88.6065),\n",
    "        (\"Namchi\", 27.1667, 88.3500),\n",
    "        (\"Gyalshing\", 27.2833, 88.2500),\n",
    "        (\"Mangan\", 27.5167, 88.5333),\n",
    "        (\"Rangpo\", 27.1833, 88.5167),\n",
    "    ],\n",
    "    \"Tamil Nadu\": [\n",
    "        (\"Chennai\", 13.0827, 80.2707),\n",
    "        (\"Coimbatore\", 11.0168, 76.9558),\n",
    "        (\"Madurai\", 9.9252, 78.1198),\n",
    "        (\"Tiruchirappalli\", 10.7905, 78.7047),\n",
    "        (\"Salem\", 11.6643, 78.1460),\n",
    "    ],\n",
    "    \"Telangana\": [\n",
    "        (\"Hyderabad\", 17.3850, 78.4867),\n",
    "        (\"Warangal\", 17.9784, 79.5941),\n",
    "        (\"Nizamabad\", 18.6725, 78.0940),\n",
    "        (\"Karimnagar\", 18.4386, 79.1288),\n",
    "        (\"Khammam\", 17.2473, 80.1514),\n",
    "    ],\n",
    "    \"Tripura\": [\n",
    "        (\"Agartala\", 23.8315, 91.2868),\n",
    "        (\"Dharmanagar\", 24.3667, 92.1667),\n",
    "        (\"Udaipur\", 23.5333, 91.4833),\n",
    "        (\"Kailashahar\", 24.3333, 92.0167),\n",
    "        (\"Belonia\", 23.2500, 91.4500),\n",
    "    ],\n",
    "    \"Uttar Pradesh\": [\n",
    "        (\"Lucknow\", 26.8467, 80.9462),\n",
    "        (\"Kanpur\", 26.4499, 80.3319),\n",
    "        (\"Varanasi\", 25.3176, 82.9739),\n",
    "        (\"Agra\", 27.1767, 78.0081),\n",
    "        (\"Noida\", 28.5355, 77.3910),\n",
    "    ],\n",
    "    \"Uttarakhand\": [\n",
    "        (\"Dehradun\", 30.3165, 78.0322),\n",
    "        (\"Haridwar\", 29.9457, 78.1642),\n",
    "        (\"Rishikesh\", 30.0869, 78.2676),\n",
    "        (\"Nainital\", 29.3919, 79.4542),\n",
    "        (\"Haldwani\", 29.2183, 79.5130),\n",
    "    ],\n",
    "    \"West Bengal\": [\n",
    "        (\"Kolkata\", 22.5726, 88.3639),\n",
    "        (\"Howrah\", 22.5958, 88.2636),\n",
    "        (\"Durgapur\", 23.5204, 87.3119),\n",
    "        (\"Siliguri\", 26.7271, 88.6393),\n",
    "        (\"Asansol\", 23.6889, 86.9661),\n",
    "    ],\n",
    "    # Union Territories\n",
    "    \"Delhi\": [\n",
    "        (\"New Delhi\", 28.6139, 77.2090),\n",
    "        (\"Dwarka\", 28.5921, 77.0460),\n",
    "        (\"Rohini\", 28.7495, 77.0565),\n",
    "        (\"Shahdara\", 28.6731, 77.2868),\n",
    "        (\"Najafgarh\", 28.6092, 76.9798),\n",
    "    ],\n",
    "    \"Chandigarh\": [\n",
    "        (\"Chandigarh Sector 17\", 30.7412, 76.7684),\n",
    "        (\"Chandigarh Sector 22\", 30.7333, 76.7794),\n",
    "        (\"Chandigarh Sector 35\", 30.7233, 76.7580),\n",
    "        (\"Chandigarh Sector 43\", 30.7106, 76.7451),\n",
    "        (\"Manimajra\", 30.7333, 76.8333),\n",
    "    ],\n",
    "    \"Puducherry\": [\n",
    "        (\"Puducherry\", 11.9416, 79.8083),\n",
    "        (\"Karaikal\", 10.9254, 79.8380),\n",
    "        (\"Mahe\", 11.7036, 75.5360),\n",
    "        (\"Yanam\", 16.7333, 82.2167),\n",
    "        (\"Ozhukarai\", 11.9500, 79.7667),\n",
    "    ],\n",
    "    \"Jammu and Kashmir\": [\n",
    "        (\"Srinagar\", 34.0837, 74.7973),\n",
    "        (\"Jammu\", 32.7266, 74.8570),\n",
    "        (\"Anantnag\", 33.7311, 75.1487),\n",
    "        (\"Baramulla\", 34.2095, 74.3436),\n",
    "        (\"Udhampur\", 32.9160, 75.1322),\n",
    "    ],\n",
    "    \"Ladakh\": [\n",
    "        (\"Leh\", 34.1526, 77.5771),\n",
    "        (\"Kargil\", 34.5539, 76.1349),\n",
    "        (\"Diskit\", 34.5500, 77.5500),\n",
    "        (\"Nyoma\", 33.2000, 78.6500),\n",
    "        (\"Zanskar\", 33.7500, 76.8500),\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(f\"Configured {len(INDIA_STATES_DISTRICTS)} states/UTs\")\n",
    "total_districts = sum(len(districts) for districts in INDIA_STATES_DISTRICTS.values())\n",
    "print(f\"Total districts to query: {total_districts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae24f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Import Libraries and Define Helper Functions\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from openaq import OpenAQ\n",
    "\n",
    "# Search radius in meters (25 km)\n",
    "RADIUS_METERS = 25000\n",
    "\n",
    "# Define date range: last 30 days to today\n",
    "date_to = datetime.datetime.now(datetime.timezone.utc)\n",
    "date_from = date_to - datetime.timedelta(days=30)\n",
    "\n",
    "print(f\"Date range: {date_from.strftime('%Y-%m-%d')} to {date_to.strftime('%Y-%m-%d')}\")\n",
    "print(f\"Search radius: {RADIUS_METERS/1000} km\")\n",
    "\n",
    "# Define the parameters we want to collect (flexible matching)\n",
    "WANTED_KEYWORDS = {\n",
    "    \"pm25\": [\"pm25\", \"pm2.5\", \"pm2_5\"],\n",
    "    \"pm10\": [\"pm10\"],\n",
    "    \"no2\": [\"no2\", \"nitrogen dioxide\"],\n",
    "    \"co\": [\"co\", \"carbon monoxide\"],\n",
    "    \"so2\": [\"so2\", \"sulfur dioxide\", \"sulphur dioxide\"],\n",
    "    \"o3\": [\"o3\", \"ozone\"],\n",
    "    \"temperature\": [\"temperature\", \"temp\", \"at\"],\n",
    "    \"humidity\": [\"humidity\", \"rh\", \"relativehumidity\", \"relative humidity\"],\n",
    "    \"wind_speed\": [\"windspeed\", \"wind_speed\", \"ws\", \"wind speed\"],\n",
    "    \"wind_direction\": [\"winddirection\", \"wind_direction\", \"wd\", \"wind direction\"]\n",
    "}\n",
    "\n",
    "# Global set to track already-used location IDs (prevents duplicate data)\n",
    "used_location_ids = set()\n",
    "\n",
    "def is_wanted_parameter(param_name):\n",
    "    \"\"\"Check if parameter name matches any of our wanted parameters\"\"\"\n",
    "    if not param_name:\n",
    "        return None\n",
    "    param_lower = param_name.lower().strip()\n",
    "    for category, keywords in WANTED_KEYWORDS.items():\n",
    "        for kw in keywords:\n",
    "            if kw == param_lower or param_lower.startswith(kw):\n",
    "                return category\n",
    "    return None\n",
    "\n",
    "def get_sensor_param_info(sensor):\n",
    "    \"\"\"Extract parameter info from sensor, handling both dict and object responses\"\"\"\n",
    "    param_name = \"\"\n",
    "    param_display = \"\"\n",
    "    param_units = \"\"\n",
    "    \n",
    "    if hasattr(sensor, 'parameter'):\n",
    "        param = sensor.parameter\n",
    "        # Handle dict response\n",
    "        if isinstance(param, dict):\n",
    "            param_name = param.get('name', '')\n",
    "            param_display = param.get('display_name', param_name)\n",
    "            param_units = param.get('units', '')\n",
    "        # Handle object response\n",
    "        else:\n",
    "            if hasattr(param, 'name') and param.name:\n",
    "                param_name = param.name\n",
    "            if hasattr(param, 'display_name') and param.display_name:\n",
    "                param_display = param.display_name\n",
    "            if hasattr(param, 'units') and param.units:\n",
    "                param_units = param.units\n",
    "    \n",
    "    # If still empty, try the sensor name\n",
    "    if not param_name and hasattr(sensor, 'name') and sensor.name:\n",
    "        param_name = sensor.name.split()[0] if sensor.name else \"\"\n",
    "        param_display = sensor.name\n",
    "    \n",
    "    return param_name, param_display, param_units\n",
    "\n",
    "def fetch_district_data(client, state_name, district_name, latitude, longitude, date_from, date_to):\n",
    "    \"\"\"\n",
    "    Fetch air quality data for a specific district.\n",
    "    Uses only ONE unique location that hasn't been used before.\n",
    "    \"\"\"\n",
    "    global used_location_ids\n",
    "    district_data = []\n",
    "    \n",
    "    try:\n",
    "        # Fetch locations around the district\n",
    "        loc_response = client.locations.list(\n",
    "            coordinates=(latitude, longitude),\n",
    "            radius=RADIUS_METERS,\n",
    "            limit=100\n",
    "        )\n",
    "        locations = loc_response.results\n",
    "        \n",
    "        if not locations:\n",
    "            return district_data, 0, None, \"no_stations\"\n",
    "        \n",
    "        # Find the first location that hasn't been used yet\n",
    "        selected_loc = None\n",
    "        for loc in locations:\n",
    "            if loc.id not in used_location_ids:\n",
    "                selected_loc = loc\n",
    "                break\n",
    "        \n",
    "        # If all locations were already used, skip this district\n",
    "        if selected_loc is None:\n",
    "            return district_data, len(locations), None, \"all_used\"\n",
    "        \n",
    "        # Mark this location as used\n",
    "        used_location_ids.add(selected_loc.id)\n",
    "        \n",
    "        loc_id = selected_loc.id\n",
    "        loc_name = selected_loc.name\n",
    "        loc_lat = selected_loc.coordinates.latitude\n",
    "        loc_lon = selected_loc.coordinates.longitude\n",
    "        \n",
    "        # Get sensors for this location\n",
    "        try:\n",
    "            sensors_response = client.locations.sensors(loc_id)\n",
    "            sensors = sensors_response.results\n",
    "        except Exception:\n",
    "            return district_data, len(locations), loc_name, \"sensor_error\"\n",
    "        \n",
    "        # For each sensor, fetch measurements if it's a wanted parameter\n",
    "        for sensor in sensors:\n",
    "            sensor_id = sensor.id\n",
    "            param_name, param_display, param_units = get_sensor_param_info(sensor)\n",
    "            \n",
    "            matched_category = is_wanted_parameter(param_name)\n",
    "            if not matched_category:\n",
    "                continue\n",
    "            \n",
    "            # Fetch measurements with pagination\n",
    "            page = 1\n",
    "            while True:\n",
    "                try:\n",
    "                    meas_response = client.measurements.list(\n",
    "                        sensors_id=sensor_id,\n",
    "                        datetime_from=date_from,\n",
    "                        datetime_to=date_to,\n",
    "                        page=page,\n",
    "                        limit=1000\n",
    "                    )\n",
    "                    results = meas_response.results\n",
    "                    \n",
    "                    if not results:\n",
    "                        break\n",
    "                    \n",
    "                    for m in results:\n",
    "                        datetime_utc = None\n",
    "                        datetime_local = None\n",
    "                        \n",
    "                        if hasattr(m, 'period') and m.period:\n",
    "                            if hasattr(m.period, 'datetime_from'):\n",
    "                                dt_from = m.period.datetime_from\n",
    "                                if hasattr(dt_from, 'utc'):\n",
    "                                    datetime_utc = str(dt_from.utc)\n",
    "                                if hasattr(dt_from, 'local'):\n",
    "                                    datetime_local = str(dt_from.local)\n",
    "                        \n",
    "                        record = {\n",
    "                            \"state\": state_name,\n",
    "                            \"district\": district_name,\n",
    "                            \"location_id\": loc_id,\n",
    "                            \"location_name\": loc_name,\n",
    "                            \"sensor_id\": sensor_id,\n",
    "                            \"parameter\": matched_category,\n",
    "                            \"parameter_original\": param_name,\n",
    "                            \"parameter_display\": param_display,\n",
    "                            \"value\": m.value if hasattr(m, 'value') else None,\n",
    "                            \"unit\": param_units,\n",
    "                            \"datetime_utc\": datetime_utc,\n",
    "                            \"datetime_local\": datetime_local,\n",
    "                            \"latitude\": loc_lat,\n",
    "                            \"longitude\": loc_lon,\n",
    "                        }\n",
    "                        district_data.append(record)\n",
    "                    \n",
    "                    page += 1\n",
    "                    time.sleep(0.05)  # Rate limiting\n",
    "                    \n",
    "                except Exception:\n",
    "                    break\n",
    "        \n",
    "        return district_data, len(locations), loc_name, \"success\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return district_data, 0, None, \"error\"\n",
    "\n",
    "print(\"Helper functions defined successfully!\")\n",
    "print(\"Note: Each location will only be used ONCE across all districts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e53f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Main Data Collection Loop\n",
    "\n",
    "# Reset the used locations tracker (important if re-running)\n",
    "used_location_ids.clear()\n",
    "\n",
    "# Initialize the OpenAQ client\n",
    "client = OpenAQ(api_key=OPENAQ_API_KEY)\n",
    "\n",
    "# Store all collected data\n",
    "all_india_data = []\n",
    "\n",
    "# Statistics tracking\n",
    "stats = {\n",
    "    \"states_processed\": 0,\n",
    "    \"districts_with_data\": 0,\n",
    "    \"districts_without_stations\": 0,\n",
    "    \"districts_skipped_duplicate\": 0,\n",
    "    \"districts_no_params\": 0,\n",
    "    \"total_records\": 0,\n",
    "    \"unique_locations_used\": 0\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Starting India-wide Air Quality Data Collection\")\n",
    "print(\"(Using ONLY 1 UNIQUE location per district - no duplicates)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for state_name, districts in INDIA_STATES_DISTRICTS.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {state_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    state_records = 0\n",
    "    \n",
    "    for district_name, lat, lon in districts:\n",
    "        print(f\"  ðŸ“ {district_name} ({lat:.4f}, {lon:.4f})...\", end=\" \")\n",
    "        \n",
    "        district_data, num_locations, location_used, status = fetch_district_data(\n",
    "            client, state_name, district_name, lat, lon, date_from, date_to\n",
    "        )\n",
    "        \n",
    "        if status == \"success\" and district_data:\n",
    "            all_india_data.extend(district_data)\n",
    "            stats[\"districts_with_data\"] += 1\n",
    "            stats[\"unique_locations_used\"] += 1\n",
    "            state_records += len(district_data)\n",
    "            print(f\"âœ“ {len(district_data)} records from '{location_used}'\")\n",
    "        elif status == \"all_used\":\n",
    "            stats[\"districts_skipped_duplicate\"] += 1\n",
    "            print(f\"â­ï¸ Skipped (all {num_locations} nearby stations already used)\")\n",
    "        elif status == \"no_stations\":\n",
    "            stats[\"districts_without_stations\"] += 1\n",
    "            print(f\"âœ— No monitoring stations found\")\n",
    "        elif status == \"success\" and not district_data:\n",
    "            stats[\"districts_no_params\"] += 1\n",
    "            print(f\"âš ï¸ Station found but no matching parameters\")\n",
    "        else:\n",
    "            stats[\"districts_without_stations\"] += 1\n",
    "            print(f\"âœ— Error fetching data\")\n",
    "        \n",
    "        # Small delay between districts\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    stats[\"states_processed\"] += 1\n",
    "    stats[\"total_records\"] += state_records\n",
    "    print(f\"  ðŸ“Š State total: {state_records} records\")\n",
    "\n",
    "# Close the client\n",
    "client.close()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Data Collection Complete!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"States/UTs processed: {stats['states_processed']}\")\n",
    "print(f\"Districts with data: {stats['districts_with_data']}\")\n",
    "print(f\"Districts skipped (duplicate stations): {stats['districts_skipped_duplicate']}\")\n",
    "print(f\"Districts without stations: {stats['districts_without_stations']}\")\n",
    "print(f\"Districts with no matching params: {stats['districts_no_params']}\")\n",
    "print(f\"Unique monitoring locations used: {stats['unique_locations_used']}\")\n",
    "print(f\"Total records collected: {stats['total_records']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c9585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Build DataFrame and Save Data\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(all_india_data)\n",
    "\n",
    "print(f\"Total records in DataFrame: {len(df)}\")\n",
    "\n",
    "if len(df) > 0:\n",
    "    # Display data preview\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Data Preview:\")\n",
    "    print(\"=\"*60)\n",
    "    print(df.head(10))\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Summary by State:\")\n",
    "    print(\"=\"*60)\n",
    "    state_summary = df.groupby('state').agg({\n",
    "        'district': 'nunique',\n",
    "        'location_id': 'nunique',\n",
    "        'value': 'count'\n",
    "    }).rename(columns={\n",
    "        'district': 'districts',\n",
    "        'location_id': 'locations',\n",
    "        'value': 'records'\n",
    "    })\n",
    "    print(state_summary)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Parameter Distribution:\")\n",
    "    print(\"=\"*60)\n",
    "    print(df['parameter'].value_counts())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Data Summary by Parameter:\")\n",
    "    print(\"=\"*60)\n",
    "    param_summary = df.groupby('parameter')['value'].agg(['count', 'mean', 'min', 'max'])\n",
    "    print(param_summary)\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = \"data/india_states\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save complete dataset\n",
    "    output_file = f\"{output_dir}/india_all_states_aq_last30days.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nâœ… Saved complete dataset to: {output_file}\")\n",
    "    \n",
    "    # Save state-wise files\n",
    "    print(\"\\nSaving state-wise files...\")\n",
    "    for state in df['state'].unique():\n",
    "        state_df = df[df['state'] == state]\n",
    "        state_filename = state.lower().replace(' ', '_').replace('and', '').replace('__', '_')\n",
    "        state_file = f\"{output_dir}/{state_filename}_aq_last30days.csv\"\n",
    "        state_df.to_csv(state_file, index=False)\n",
    "        print(f\"   âœ… {state}: {len(state_df)} records -> {state_file}\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ‰ All data saved to '{output_dir}' directory!\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nâŒ No data collected. This could mean:\")\n",
    "    print(\"   - No monitoring stations exist in the searched areas\")\n",
    "    print(\"   - No data available for the last 30 days\")\n",
    "    print(\"   - API rate limits or connectivity issues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e7bffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Generate Summary Report\n",
    "\n",
    "if len(df) > 0:\n",
    "    print(\"=\"*70)\n",
    "    print(\"INDIA AIR QUALITY DATA COLLECTION - FINAL REPORT\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nðŸ“… Data Period: {date_from.strftime('%Y-%m-%d')} to {date_to.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"ðŸ“Š Total Records: {len(df):,}\")\n",
    "    print(f\"ðŸ—ºï¸  States/UTs with data: {df['state'].nunique()}\")\n",
    "    print(f\"ðŸ“ Districts with data: {df['district'].nunique()}\")\n",
    "    print(f\"ðŸ­ Monitoring Locations: {df['location_id'].nunique()}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"Parameters Collected:\")\n",
    "    print(\"-\"*50)\n",
    "    for param in df['parameter'].unique():\n",
    "        param_data = df[df['parameter'] == param]\n",
    "        print(f\"  â€¢ {param.upper()}: {len(param_data):,} measurements\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"Top 10 States by Data Volume:\")\n",
    "    print(\"-\"*50)\n",
    "    top_states = df.groupby('state').size().sort_values(ascending=False).head(10)\n",
    "    for i, (state, count) in enumerate(top_states.items(), 1):\n",
    "        print(f\"  {i:2}. {state}: {count:,} records\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"Output Files:\")\n",
    "    print(\"-\"*50)\n",
    "    print(f\"  ðŸ“ Main file: data/india_states/india_all_states_aq_last30days.csv\")\n",
    "    print(f\"  ðŸ“ State files: data/india_states/[state_name]_aq_last30days.csv\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"âœ… Data collection completed successfully!\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"No data to generate report.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd00eca",
   "metadata": {},
   "source": [
    "# Data Transformation\n",
    "\n",
    "Transform the collected data by pivoting parameter values into separate feature columns.\n",
    "Each unique parameter (pm25, pm10, no2, co, so2, o3, temperature, humidity, wind_speed, wind_direction) becomes its own column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fef6f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING COMPLETE INDIA AIR QUALITY DATASET\n",
      "======================================================================\n",
      "\n",
      "âœ… Loaded: data/india_states/india_all_states_aq_last30days.csv\n",
      "\n",
      "ðŸ“Š Dataset Statistics:\n",
      "   Total records: 978,897\n",
      "   States/UTs: 19\n",
      "   Districts: 49\n",
      "   Unique Locations: 49\n",
      "   Parameters: ['pm25', 'o3', 'co', 'pm10', 'humidity', 'temperature', 'so2', 'no2', 'wind_speed', 'wind_direction']\n",
      "\n",
      "--------------------------------------------------\n",
      "Records per State:\n",
      "--------------------------------------------------\n",
      "   Punjab: 108,482 records\n",
      "   Chhattisgarh: 97,180 records\n",
      "   Madhya Pradesh: 89,237 records\n",
      "   Kerala: 77,884 records\n",
      "   Gujarat: 73,395 records\n",
      "   Andhra Pradesh: 68,901 records\n",
      "   Odisha: 68,370 records\n",
      "   Rajasthan: 67,508 records\n",
      "   Haryana: 60,982 records\n",
      "   Maharashtra: 56,719 records\n",
      "   Bihar: 42,569 records\n",
      "   Meghalaya: 41,239 records\n",
      "   Assam: 25,638 records\n",
      "   Nagaland: 24,560 records\n",
      "   Arunachal Pradesh: 20,240 records\n",
      "   Karnataka: 18,152 records\n",
      "   Mizoram: 13,764 records\n",
      "   Sikkim: 13,065 records\n",
      "   Jharkhand: 11,012 records\n",
      "\n",
      "   TOTAL: 978,897 records\n",
      "\n",
      "--------------------------------------------------\n",
      "Sample Data (before transformation):\n",
      "--------------------------------------------------\n",
      "            state       district  location_id  \\\n",
      "0  Andhra Pradesh  Visakhapatnam         5628   \n",
      "1  Andhra Pradesh  Visakhapatnam         5628   \n",
      "2  Andhra Pradesh  Visakhapatnam         5628   \n",
      "3  Andhra Pradesh  Visakhapatnam         5628   \n",
      "4  Andhra Pradesh  Visakhapatnam         5628   \n",
      "\n",
      "                            location_name  sensor_id parameter  \\\n",
      "0  GVM Corporation, Visakhapatnam - APPCB   12235460      pm25   \n",
      "1  GVM Corporation, Visakhapatnam - APPCB   12235460      pm25   \n",
      "2  GVM Corporation, Visakhapatnam - APPCB   12235460      pm25   \n",
      "3  GVM Corporation, Visakhapatnam - APPCB   12235460      pm25   \n",
      "4  GVM Corporation, Visakhapatnam - APPCB   12235460      pm25   \n",
      "\n",
      "  parameter_original parameter_display  value   unit          datetime_utc  \\\n",
      "0               pm25             PM2.5   41.0  Âµg/mÂ³  2025-11-08T09:45:00Z   \n",
      "1               pm25             PM2.5   55.0  Âµg/mÂ³  2025-11-08T10:00:00Z   \n",
      "2               pm25             PM2.5   55.0  Âµg/mÂ³  2025-11-08T10:15:00Z   \n",
      "3               pm25             PM2.5   55.0  Âµg/mÂ³  2025-11-08T10:30:00Z   \n",
      "4               pm25             PM2.5   55.0  Âµg/mÂ³  2025-11-08T10:45:00Z   \n",
      "\n",
      "              datetime_local   latitude  longitude  \n",
      "0  2025-11-08T15:15:00+05:30  17.722682  83.308197  \n",
      "1  2025-11-08T15:30:00+05:30  17.722682  83.308197  \n",
      "2  2025-11-08T15:45:00+05:30  17.722682  83.308197  \n",
      "3  2025-11-08T16:00:00+05:30  17.722682  83.308197  \n",
      "4  2025-11-08T16:15:00+05:30  17.722682  83.308197  \n",
      "\n",
      "âœ… Loaded: data/india_states/india_all_states_aq_last30days.csv\n",
      "\n",
      "ðŸ“Š Dataset Statistics:\n",
      "   Total records: 978,897\n",
      "   States/UTs: 19\n",
      "   Districts: 49\n",
      "   Unique Locations: 49\n",
      "   Parameters: ['pm25', 'o3', 'co', 'pm10', 'humidity', 'temperature', 'so2', 'no2', 'wind_speed', 'wind_direction']\n",
      "\n",
      "--------------------------------------------------\n",
      "Records per State:\n",
      "--------------------------------------------------\n",
      "   Punjab: 108,482 records\n",
      "   Chhattisgarh: 97,180 records\n",
      "   Madhya Pradesh: 89,237 records\n",
      "   Kerala: 77,884 records\n",
      "   Gujarat: 73,395 records\n",
      "   Andhra Pradesh: 68,901 records\n",
      "   Odisha: 68,370 records\n",
      "   Rajasthan: 67,508 records\n",
      "   Haryana: 60,982 records\n",
      "   Maharashtra: 56,719 records\n",
      "   Bihar: 42,569 records\n",
      "   Meghalaya: 41,239 records\n",
      "   Assam: 25,638 records\n",
      "   Nagaland: 24,560 records\n",
      "   Arunachal Pradesh: 20,240 records\n",
      "   Karnataka: 18,152 records\n",
      "   Mizoram: 13,764 records\n",
      "   Sikkim: 13,065 records\n",
      "   Jharkhand: 11,012 records\n",
      "\n",
      "   TOTAL: 978,897 records\n",
      "\n",
      "--------------------------------------------------\n",
      "Sample Data (before transformation):\n",
      "--------------------------------------------------\n",
      "            state       district  location_id  \\\n",
      "0  Andhra Pradesh  Visakhapatnam         5628   \n",
      "1  Andhra Pradesh  Visakhapatnam         5628   \n",
      "2  Andhra Pradesh  Visakhapatnam         5628   \n",
      "3  Andhra Pradesh  Visakhapatnam         5628   \n",
      "4  Andhra Pradesh  Visakhapatnam         5628   \n",
      "\n",
      "                            location_name  sensor_id parameter  \\\n",
      "0  GVM Corporation, Visakhapatnam - APPCB   12235460      pm25   \n",
      "1  GVM Corporation, Visakhapatnam - APPCB   12235460      pm25   \n",
      "2  GVM Corporation, Visakhapatnam - APPCB   12235460      pm25   \n",
      "3  GVM Corporation, Visakhapatnam - APPCB   12235460      pm25   \n",
      "4  GVM Corporation, Visakhapatnam - APPCB   12235460      pm25   \n",
      "\n",
      "  parameter_original parameter_display  value   unit          datetime_utc  \\\n",
      "0               pm25             PM2.5   41.0  Âµg/mÂ³  2025-11-08T09:45:00Z   \n",
      "1               pm25             PM2.5   55.0  Âµg/mÂ³  2025-11-08T10:00:00Z   \n",
      "2               pm25             PM2.5   55.0  Âµg/mÂ³  2025-11-08T10:15:00Z   \n",
      "3               pm25             PM2.5   55.0  Âµg/mÂ³  2025-11-08T10:30:00Z   \n",
      "4               pm25             PM2.5   55.0  Âµg/mÂ³  2025-11-08T10:45:00Z   \n",
      "\n",
      "              datetime_local   latitude  longitude  \n",
      "0  2025-11-08T15:15:00+05:30  17.722682  83.308197  \n",
      "1  2025-11-08T15:30:00+05:30  17.722682  83.308197  \n",
      "2  2025-11-08T15:45:00+05:30  17.722682  83.308197  \n",
      "3  2025-11-08T16:00:00+05:30  17.722682  83.308197  \n",
      "4  2025-11-08T16:15:00+05:30  17.722682  83.308197  \n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Load the Complete Combined Dataset (ALL RECORDS)\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to the main combined data file\n",
    "data_dir = \"data/india_states\"\n",
    "main_file = f\"{data_dir}/india_all_states_aq_last30days.csv\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING COMPLETE INDIA AIR QUALITY DATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load the main combined file which contains ALL records\n",
    "if os.path.exists(main_file):\n",
    "    combined_df = pd.read_csv(main_file)\n",
    "    print(f\"\\nâœ… Loaded: {main_file}\")\n",
    "    print(f\"\\nðŸ“Š Dataset Statistics:\")\n",
    "    print(f\"   Total records: {len(combined_df):,}\")\n",
    "    print(f\"   States/UTs: {combined_df['state'].nunique()}\")\n",
    "    print(f\"   Districts: {combined_df['district'].nunique()}\")\n",
    "    print(f\"   Unique Locations: {combined_df['location_id'].nunique()}\")\n",
    "    print(f\"   Parameters: {combined_df['parameter'].unique().tolist()}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"Records per State:\")\n",
    "    print(\"-\"*50)\n",
    "    state_counts = combined_df.groupby('state').size().sort_values(ascending=False)\n",
    "    for state, count in state_counts.items():\n",
    "        print(f\"   {state}: {count:,} records\")\n",
    "    \n",
    "    print(f\"\\n   TOTAL: {state_counts.sum():,} records\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"Sample Data (before transformation):\")\n",
    "    print(\"-\"*50)\n",
    "    print(combined_df.head())\n",
    "else:\n",
    "    print(f\"âŒ File not found: {main_file}\")\n",
    "    combined_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "862c1df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRANSFORMING DATA: PIVOTING PARAMETERS INTO FEATURE COLUMNS\n",
      "======================================================================\n",
      "\n",
      "Input records: 978,897\n",
      "Available index columns: ['state', 'district', 'location_id', 'location_name', 'datetime_utc', 'datetime_local', 'latitude', 'longitude']\n",
      "\n",
      "âœ… Transformation complete!\n",
      "\n",
      "ðŸ“Š Transformation Results:\n",
      "   Original records: 978,897\n",
      "   Transformed rows: 109,501\n",
      "   Total columns: 18\n",
      "\n",
      "ðŸ“‹ Index columns: ['state', 'district', 'location_id', 'location_name', 'datetime_utc', 'datetime_local', 'latitude', 'longitude']\n",
      "ðŸ“‹ Parameter feature columns: ['co', 'humidity', 'no2', 'o3', 'pm10', 'pm25', 'so2', 'temperature', 'wind_direction', 'wind_speed']\n",
      "\n",
      "--------------------------------------------------\n",
      "Data Preservation Check:\n",
      "--------------------------------------------------\n",
      "   co: Original=100,818, Transformed=100,818\n",
      "   humidity: Original=93,526, Transformed=93,526\n",
      "   no2: Original=105,891, Transformed=105,891\n",
      "   o3: Original=98,644, Transformed=98,644\n",
      "\n",
      "âœ… Transformation complete!\n",
      "\n",
      "ðŸ“Š Transformation Results:\n",
      "   Original records: 978,897\n",
      "   Transformed rows: 109,501\n",
      "   Total columns: 18\n",
      "\n",
      "ðŸ“‹ Index columns: ['state', 'district', 'location_id', 'location_name', 'datetime_utc', 'datetime_local', 'latitude', 'longitude']\n",
      "ðŸ“‹ Parameter feature columns: ['co', 'humidity', 'no2', 'o3', 'pm10', 'pm25', 'so2', 'temperature', 'wind_direction', 'wind_speed']\n",
      "\n",
      "--------------------------------------------------\n",
      "Data Preservation Check:\n",
      "--------------------------------------------------\n",
      "   co: Original=100,818, Transformed=100,818\n",
      "   humidity: Original=93,526, Transformed=93,526\n",
      "   no2: Original=105,891, Transformed=105,891\n",
      "   o3: Original=98,644, Transformed=98,644\n",
      "   pm10: Original=101,126, Transformed=101,126\n",
      "   pm25: Original=105,683, Transformed=105,683\n",
      "   so2: Original=106,879, Transformed=106,879\n",
      "   temperature: Original=85,780, Transformed=85,780\n",
      "   wind_direction: Original=91,464, Transformed=91,464\n",
      "   pm10: Original=101,126, Transformed=101,126\n",
      "   pm25: Original=105,683, Transformed=105,683\n",
      "   so2: Original=106,879, Transformed=106,879\n",
      "   temperature: Original=85,780, Transformed=85,780\n",
      "   wind_direction: Original=91,464, Transformed=91,464\n",
      "   wind_speed: Original=89,086, Transformed=89,086\n",
      "\n",
      "--------------------------------------------------\n",
      "Transformed Data Preview:\n",
      "--------------------------------------------------\n",
      "            state  district  location_id               location_name  \\\n",
      "0  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "1  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "2  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "3  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "4  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "5  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "6  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "7  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "8  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "9  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "\n",
      "           datetime_utc             datetime_local  latitude  longitude    co  \\\n",
      "0  2025-11-08T09:45:00Z  2025-11-08T15:15:00+05:30     13.67      79.35  0.61   \n",
      "1  2025-11-08T10:00:00Z  2025-11-08T15:30:00+05:30     13.67      79.35  0.69   \n",
      "2  2025-11-08T10:15:00Z  2025-11-08T15:45:00+05:30     13.67      79.35  0.54   \n",
      "3  2025-11-08T10:30:00Z  2025-11-08T16:00:00+05:30     13.67      79.35  0.61   \n",
      "4  2025-11-08T10:45:00Z  2025-11-08T16:15:00+05:30     13.67      79.35  0.68   \n",
      "5  2025-11-08T11:00:00Z  2025-11-08T16:30:00+05:30     13.67      79.35  0.55   \n",
      "6  2025-11-08T11:15:00Z  2025-11-08T16:45:00+05:30     13.67      79.35  0.52   \n",
      "7  2025-11-08T11:30:00Z  2025-11-08T17:00:00+05:30     13.67      79.35  0.72   \n",
      "8  2025-11-08T11:45:00Z  2025-11-08T17:15:00+05:30     13.67      79.35  0.74   \n",
      "9  2025-11-08T12:00:00Z  2025-11-08T17:30:00+05:30     13.67      79.35  0.69   \n",
      "\n",
      "   humidity   no2    o3  pm10  pm25  so2  temperature  wind_direction  \\\n",
      "0      58.0  18.6  33.0  63.0  25.0  4.9         24.7           355.0   \n",
      "1      59.0  16.7  33.8  66.0  33.0  4.9         24.6           355.0   \n",
      "2      59.0  19.2  31.2  66.0  33.0  5.1         24.5           355.0   \n",
      "3      60.0  20.6  29.2  66.0  33.0  5.0         24.4           355.0   \n",
      "4      60.0  18.9  29.7  66.0  33.0  5.0         24.3           355.0   \n",
      "5      61.0  18.9  31.4  64.0  36.0  4.8         24.1           355.0   \n",
      "6      62.0  18.3  32.2  64.0  36.0  5.0         23.9           355.0   \n",
      "7      63.0  21.1  31.1  64.0  36.0  5.0         23.7           355.0   \n",
      "8      64.0  22.2  25.9  64.0  36.0  5.0         23.6           355.0   \n",
      "9      65.0  25.4  21.2  68.0  45.0  4.8         23.4           355.0   \n",
      "\n",
      "   wind_speed  \n",
      "0         0.3  \n",
      "1         0.5  \n",
      "2         0.6  \n",
      "3         0.5  \n",
      "4         0.3  \n",
      "5         0.3  \n",
      "6         0.3  \n",
      "7         0.3  \n",
      "8         0.3  \n",
      "9         0.3  \n",
      "   wind_speed: Original=89,086, Transformed=89,086\n",
      "\n",
      "--------------------------------------------------\n",
      "Transformed Data Preview:\n",
      "--------------------------------------------------\n",
      "            state  district  location_id               location_name  \\\n",
      "0  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "1  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "2  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "3  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "4  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "5  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "6  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "7  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "8  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "9  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "\n",
      "           datetime_utc             datetime_local  latitude  longitude    co  \\\n",
      "0  2025-11-08T09:45:00Z  2025-11-08T15:15:00+05:30     13.67      79.35  0.61   \n",
      "1  2025-11-08T10:00:00Z  2025-11-08T15:30:00+05:30     13.67      79.35  0.69   \n",
      "2  2025-11-08T10:15:00Z  2025-11-08T15:45:00+05:30     13.67      79.35  0.54   \n",
      "3  2025-11-08T10:30:00Z  2025-11-08T16:00:00+05:30     13.67      79.35  0.61   \n",
      "4  2025-11-08T10:45:00Z  2025-11-08T16:15:00+05:30     13.67      79.35  0.68   \n",
      "5  2025-11-08T11:00:00Z  2025-11-08T16:30:00+05:30     13.67      79.35  0.55   \n",
      "6  2025-11-08T11:15:00Z  2025-11-08T16:45:00+05:30     13.67      79.35  0.52   \n",
      "7  2025-11-08T11:30:00Z  2025-11-08T17:00:00+05:30     13.67      79.35  0.72   \n",
      "8  2025-11-08T11:45:00Z  2025-11-08T17:15:00+05:30     13.67      79.35  0.74   \n",
      "9  2025-11-08T12:00:00Z  2025-11-08T17:30:00+05:30     13.67      79.35  0.69   \n",
      "\n",
      "   humidity   no2    o3  pm10  pm25  so2  temperature  wind_direction  \\\n",
      "0      58.0  18.6  33.0  63.0  25.0  4.9         24.7           355.0   \n",
      "1      59.0  16.7  33.8  66.0  33.0  4.9         24.6           355.0   \n",
      "2      59.0  19.2  31.2  66.0  33.0  5.1         24.5           355.0   \n",
      "3      60.0  20.6  29.2  66.0  33.0  5.0         24.4           355.0   \n",
      "4      60.0  18.9  29.7  66.0  33.0  5.0         24.3           355.0   \n",
      "5      61.0  18.9  31.4  64.0  36.0  4.8         24.1           355.0   \n",
      "6      62.0  18.3  32.2  64.0  36.0  5.0         23.9           355.0   \n",
      "7      63.0  21.1  31.1  64.0  36.0  5.0         23.7           355.0   \n",
      "8      64.0  22.2  25.9  64.0  36.0  5.0         23.6           355.0   \n",
      "9      65.0  25.4  21.2  68.0  45.0  4.8         23.4           355.0   \n",
      "\n",
      "   wind_speed  \n",
      "0         0.3  \n",
      "1         0.5  \n",
      "2         0.6  \n",
      "3         0.5  \n",
      "4         0.3  \n",
      "5         0.3  \n",
      "6         0.3  \n",
      "7         0.3  \n",
      "8         0.3  \n",
      "9         0.3  \n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Transform Data - Pivot Parameters into Feature Columns (ALL RECORDS)\n",
    "\n",
    "if len(combined_df) > 0:\n",
    "    print(\"=\"*70)\n",
    "    print(\"TRANSFORMING DATA: PIVOTING PARAMETERS INTO FEATURE COLUMNS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nInput records: {len(combined_df):,}\")\n",
    "    \n",
    "    # Define the index columns (grouping columns)\n",
    "    index_cols = [\n",
    "        'state', \n",
    "        'district', \n",
    "        'location_id', \n",
    "        'location_name', \n",
    "        'datetime_utc', \n",
    "        'datetime_local', \n",
    "        'latitude', \n",
    "        'longitude'\n",
    "    ]\n",
    "    \n",
    "    # Check which columns exist in the data\n",
    "    available_cols = [col for col in index_cols if col in combined_df.columns]\n",
    "    print(f\"Available index columns: {available_cols}\")\n",
    "    \n",
    "    # Pivot the dataframe: parameters become columns, values become the data\n",
    "    # Using 'first' instead of 'mean' to preserve all unique combinations\n",
    "    transformed_df = combined_df.pivot_table(\n",
    "        index=available_cols,\n",
    "        columns='parameter',\n",
    "        values='value',\n",
    "        aggfunc='first'  # Take first value if duplicates exist\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Flatten column names (remove multi-index)\n",
    "    transformed_df.columns.name = None\n",
    "    \n",
    "    # Get the parameter columns that were created\n",
    "    param_columns = [col for col in transformed_df.columns if col not in available_cols]\n",
    "    \n",
    "    print(f\"\\nâœ… Transformation complete!\")\n",
    "    print(f\"\\nðŸ“Š Transformation Results:\")\n",
    "    print(f\"   Original records: {len(combined_df):,}\")\n",
    "    print(f\"   Transformed rows: {len(transformed_df):,}\")\n",
    "    print(f\"   Total columns: {len(transformed_df.columns)}\")\n",
    "    print(f\"\\nðŸ“‹ Index columns: {available_cols}\")\n",
    "    print(f\"ðŸ“‹ Parameter feature columns: {param_columns}\")\n",
    "    \n",
    "    # Verify no data loss\n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"Data Preservation Check:\")\n",
    "    print(\"-\"*50)\n",
    "    for param in param_columns:\n",
    "        original_count = combined_df[combined_df['parameter'] == param]['value'].notna().sum()\n",
    "        transformed_count = transformed_df[param].notna().sum()\n",
    "        print(f\"   {param}: Original={original_count:,}, Transformed={transformed_count:,}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"Transformed Data Preview:\")\n",
    "    print(\"-\"*50)\n",
    "    print(transformed_df.head(10))\n",
    "else:\n",
    "    print(\"âŒ No data to transform!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac320703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATA QUALITY REPORT\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š Missing Values per Parameter Column:\n",
      "--------------------------------------------------\n",
      "  pm25                : 105,683 values (96.5% coverage), 3,818 missing (3.5%)\n",
      "  pm10                : 101,126 values (92.4% coverage), 8,375 missing (7.6%)\n",
      "  no2                 : 105,891 values (96.7% coverage), 3,610 missing (3.3%)\n",
      "  co                  : 100,818 values (92.1% coverage), 8,683 missing (7.9%)\n",
      "  so2                 : 106,879 values (97.6% coverage), 2,622 missing (2.4%)\n",
      "  o3                  : 98,644 values (90.1% coverage), 10,857 missing (9.9%)\n",
      "  temperature         : 85,780 values (78.3% coverage), 23,721 missing (21.7%)\n",
      "  humidity            : 93,526 values (85.4% coverage), 15,975 missing (14.6%)\n",
      "  wind_speed          : 89,086 values (81.4% coverage), 20,415 missing (18.6%)\n",
      "  wind_direction      : 91,464 values (83.5% coverage), 18,037 missing (16.5%)\n",
      "\n",
      "======================================================================\n",
      "PARAMETER STATISTICS:\n",
      "======================================================================\n",
      "     Parameter  Count         Mean          Std      Min          Max\n",
      "          pm25 105683 1.527145e+02 5.259274e+03 -9999.00 8.501912e+05\n",
      "          pm10 101126 1.356846e+02 1.107647e+03     0.00 1.766598e+05\n",
      "           no2 105891 2.247813e+01 9.532138e+01   -63.60 2.649360e+04\n",
      "            co 100818 8.159659e-01 7.226877e-01    -6.76 1.000000e+01\n",
      "           so2 106879 1.805511e+01 5.442201e+01    -4.90 1.371400e+03\n",
      "            o3  98644 2.445331e+22 4.622673e+24  -708.70 1.000168e+27\n",
      "   temperature  85780 2.080237e+01 7.691142e+00   -52.00 8.941000e+01\n",
      "      humidity  93526 6.241692e+01 2.639152e+01   -29.00 1.421800e+02\n",
      "    wind_speed  89086 3.823520e+00 1.688417e+01    -0.68 1.352300e+02\n",
      "wind_direction  91464 1.685134e+02 1.029863e+02    -4.84 3.600000e+02\n",
      "\n",
      "======================================================================\n",
      "DATA COVERAGE BY STATE:\n",
      "======================================================================\n",
      "                districts  locations  records\n",
      "state                                        \n",
      "Punjab                  5          5    11568\n",
      "Chhattisgarh            5          5    11148\n",
      "Madhya Pradesh          4          4     9770\n",
      "Gujarat                 4          4     8391\n",
      "Kerala                  4          4     7874\n",
      "Odisha                  3          3     7183\n",
      "Rajasthan               3          3     7169\n",
      "Andhra Pradesh          3          3     7149\n",
      "Haryana                 3          3     6915\n",
      "Maharashtra             3          3     5869\n",
      "Bihar                   2          2     4805\n",
      "Meghalaya               2          2     4762\n",
      "Karnataka               2          2     3761\n",
      "Assam                   1          1     2570\n",
      "Nagaland                1          1     2456\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Data Quality Check and Statistics\n",
    "\n",
    "if 'transformed_df' in dir() and len(transformed_df) > 0:\n",
    "    print(\"=\"*70)\n",
    "    print(\"DATA QUALITY REPORT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Missing values analysis\n",
    "    print(\"\\nðŸ“Š Missing Values per Parameter Column:\")\n",
    "    print(\"-\"*50)\n",
    "    param_columns = ['pm25', 'pm10', 'no2', 'co', 'so2', 'o3', 'temperature', 'humidity', 'wind_speed', 'wind_direction']\n",
    "    existing_params = [col for col in param_columns if col in transformed_df.columns]\n",
    "    \n",
    "    for col in existing_params:\n",
    "        missing = transformed_df[col].isna().sum()\n",
    "        total = len(transformed_df)\n",
    "        pct = (missing / total) * 100\n",
    "        present = total - missing\n",
    "        print(f\"  {col:20s}: {present:,} values ({100-pct:.1f}% coverage), {missing:,} missing ({pct:.1f}%)\")\n",
    "    \n",
    "    # Statistics for each parameter\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PARAMETER STATISTICS:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    stats_data = []\n",
    "    for col in existing_params:\n",
    "        if col in transformed_df.columns:\n",
    "            stats_data.append({\n",
    "                'Parameter': col,\n",
    "                'Count': transformed_df[col].notna().sum(),\n",
    "                'Mean': transformed_df[col].mean(),\n",
    "                'Std': transformed_df[col].std(),\n",
    "                'Min': transformed_df[col].min(),\n",
    "                'Max': transformed_df[col].max()\n",
    "            })\n",
    "    \n",
    "    stats_df = pd.DataFrame(stats_data)\n",
    "    print(stats_df.to_string(index=False))\n",
    "    \n",
    "    # Coverage by state\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DATA COVERAGE BY STATE:\")\n",
    "    print(\"=\"*70)\n",
    "    state_coverage = transformed_df.groupby('state').agg({\n",
    "        'district': 'nunique',\n",
    "        'location_id': 'nunique',\n",
    "        'datetime_utc': 'count'\n",
    "    }).rename(columns={\n",
    "        'district': 'districts',\n",
    "        'location_id': 'locations',\n",
    "        'datetime_utc': 'records'\n",
    "    }).sort_values('records', ascending=False)\n",
    "    \n",
    "    print(state_coverage.head(15))\n",
    "else:\n",
    "    print(\"No transformed data available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6569562e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FINAL TRANSFORMED DATASET SAVED SUCCESSFULLY!\n",
      "======================================================================\n",
      "\n",
      "ðŸ“ Output file: data/processed/india_aq_transformed_last30days.csv\n",
      "ðŸ“Š Total rows: 109,501\n",
      "ðŸ“‹ Total columns: 18\n",
      "\n",
      "--------------------------------------------------\n",
      "Final Column Structure:\n",
      "--------------------------------------------------\n",
      "   1. state                (object) - 109,501 values\n",
      "   2. district             (object) - 109,501 values\n",
      "   3. location_id          (int64) - 109,501 values\n",
      "   4. location_name        (object) - 109,501 values\n",
      "   5. datetime_utc         (object) - 109,501 values\n",
      "   6. datetime_local       (object) - 109,501 values\n",
      "   7. latitude             (float64) - 109,501 values\n",
      "   8. longitude            (float64) - 109,501 values\n",
      "   9. pm25                 (float64) - 105,683 values\n",
      "  10. pm10                 (float64) - 101,126 values\n",
      "  11. no2                  (float64) - 105,891 values\n",
      "  12. co                   (float64) - 100,818 values\n",
      "  13. so2                  (float64) - 106,879 values\n",
      "  14. o3                   (float64) - 98,644 values\n",
      "  15. temperature          (float64) - 85,780 values\n",
      "  16. humidity             (float64) - 93,526 values\n",
      "  17. wind_speed           (float64) - 89,086 values\n",
      "  18. wind_direction       (float64) - 91,464 values\n",
      "\n",
      "--------------------------------------------------\n",
      "Records per State in Final Dataset:\n",
      "--------------------------------------------------\n",
      "   Punjab: 11,568 rows\n",
      "   Chhattisgarh: 11,148 rows\n",
      "   Madhya Pradesh: 9,770 rows\n",
      "   Gujarat: 8,391 rows\n",
      "   Kerala: 7,874 rows\n",
      "   Odisha: 7,183 rows\n",
      "   Rajasthan: 7,169 rows\n",
      "   Andhra Pradesh: 7,149 rows\n",
      "   Haryana: 6,915 rows\n",
      "   Maharashtra: 5,869 rows\n",
      "   Bihar: 4,805 rows\n",
      "   Meghalaya: 4,762 rows\n",
      "   Karnataka: 3,761 rows\n",
      "   Assam: 2,570 rows\n",
      "   Nagaland: 2,456 rows\n",
      "   Sikkim: 2,413 rows\n",
      "   Mizoram: 2,294 rows\n",
      "   Arunachal Pradesh: 2,024 rows\n",
      "   Jharkhand: 1,380 rows\n",
      "\n",
      "   TOTAL ROWS: 109,501\n",
      "\n",
      "--------------------------------------------------\n",
      "Final Data Preview:\n",
      "--------------------------------------------------\n",
      "            state  district  location_id               location_name  \\\n",
      "0  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "1  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "2  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "3  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "4  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "5  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "6  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "7  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "8  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "9  Andhra Pradesh  Tirupati         5649  Tirumala, Tirupati - APPCB   \n",
      "\n",
      "           datetime_utc             datetime_local  latitude  longitude  pm25  \\\n",
      "0  2025-11-08T09:45:00Z  2025-11-08T15:15:00+05:30     13.67      79.35  25.0   \n",
      "1  2025-11-08T10:00:00Z  2025-11-08T15:30:00+05:30     13.67      79.35  33.0   \n",
      "2  2025-11-08T10:15:00Z  2025-11-08T15:45:00+05:30     13.67      79.35  33.0   \n",
      "3  2025-11-08T10:30:00Z  2025-11-08T16:00:00+05:30     13.67      79.35  33.0   \n",
      "4  2025-11-08T10:45:00Z  2025-11-08T16:15:00+05:30     13.67      79.35  33.0   \n",
      "5  2025-11-08T11:00:00Z  2025-11-08T16:30:00+05:30     13.67      79.35  36.0   \n",
      "6  2025-11-08T11:15:00Z  2025-11-08T16:45:00+05:30     13.67      79.35  36.0   \n",
      "7  2025-11-08T11:30:00Z  2025-11-08T17:00:00+05:30     13.67      79.35  36.0   \n",
      "8  2025-11-08T11:45:00Z  2025-11-08T17:15:00+05:30     13.67      79.35  36.0   \n",
      "9  2025-11-08T12:00:00Z  2025-11-08T17:30:00+05:30     13.67      79.35  45.0   \n",
      "\n",
      "   pm10   no2    co  so2    o3  temperature  humidity  wind_speed  \\\n",
      "0  63.0  18.6  0.61  4.9  33.0         24.7      58.0         0.3   \n",
      "1  66.0  16.7  0.69  4.9  33.8         24.6      59.0         0.5   \n",
      "2  66.0  19.2  0.54  5.1  31.2         24.5      59.0         0.6   \n",
      "3  66.0  20.6  0.61  5.0  29.2         24.4      60.0         0.5   \n",
      "4  66.0  18.9  0.68  5.0  29.7         24.3      60.0         0.3   \n",
      "5  64.0  18.9  0.55  4.8  31.4         24.1      61.0         0.3   \n",
      "6  64.0  18.3  0.52  5.0  32.2         23.9      62.0         0.3   \n",
      "7  64.0  21.1  0.72  5.0  31.1         23.7      63.0         0.3   \n",
      "8  64.0  22.2  0.74  5.0  25.9         23.6      64.0         0.3   \n",
      "9  68.0  25.4  0.69  4.8  21.2         23.4      65.0         0.3   \n",
      "\n",
      "   wind_direction  \n",
      "0           355.0  \n",
      "1           355.0  \n",
      "2           355.0  \n",
      "3           355.0  \n",
      "4           355.0  \n",
      "5           355.0  \n",
      "6           355.0  \n",
      "7           355.0  \n",
      "8           355.0  \n",
      "9           355.0  \n",
      "\n",
      "--------------------------------------------------\n",
      "Saving state-wise transformed files...\n",
      "--------------------------------------------------\n",
      "  âœ… Andhra Pradesh: 7,149 rows -> data/processed/hra_pradesh_aq_transformed.csv\n",
      "  âœ… Arunachal Pradesh: 2,024 rows -> data/processed/arunachal_pradesh_aq_transformed.csv\n",
      "  âœ… Assam: 2,570 rows -> data/processed/assam_aq_transformed.csv\n",
      "  âœ… Bihar: 4,805 rows -> data/processed/bihar_aq_transformed.csv\n",
      "  âœ… Chhattisgarh: 11,148 rows -> data/processed/chhattisgarh_aq_transformed.csv\n",
      "  âœ… Gujarat: 8,391 rows -> data/processed/gujarat_aq_transformed.csv\n",
      "  âœ… Bihar: 4,805 rows -> data/processed/bihar_aq_transformed.csv\n",
      "  âœ… Chhattisgarh: 11,148 rows -> data/processed/chhattisgarh_aq_transformed.csv\n",
      "  âœ… Gujarat: 8,391 rows -> data/processed/gujarat_aq_transformed.csv\n",
      "  âœ… Haryana: 6,915 rows -> data/processed/haryana_aq_transformed.csv\n",
      "  âœ… Jharkhand: 1,380 rows -> data/processed/jharkh_aq_transformed.csv\n",
      "  âœ… Karnataka: 3,761 rows -> data/processed/karnataka_aq_transformed.csv\n",
      "  âœ… Kerala: 7,874 rows -> data/processed/kerala_aq_transformed.csv\n",
      "  âœ… Haryana: 6,915 rows -> data/processed/haryana_aq_transformed.csv\n",
      "  âœ… Jharkhand: 1,380 rows -> data/processed/jharkh_aq_transformed.csv\n",
      "  âœ… Karnataka: 3,761 rows -> data/processed/karnataka_aq_transformed.csv\n",
      "  âœ… Kerala: 7,874 rows -> data/processed/kerala_aq_transformed.csv\n",
      "  âœ… Madhya Pradesh: 9,770 rows -> data/processed/madhya_pradesh_aq_transformed.csv\n",
      "  âœ… Maharashtra: 5,869 rows -> data/processed/maharashtra_aq_transformed.csv\n",
      "  âœ… Meghalaya: 4,762 rows -> data/processed/meghalaya_aq_transformed.csv\n",
      "  âœ… Mizoram: 2,294 rows -> data/processed/mizoram_aq_transformed.csv\n",
      "  âœ… Nagaland: 2,456 rows -> data/processed/nagal_aq_transformed.csv\n",
      "  âœ… Madhya Pradesh: 9,770 rows -> data/processed/madhya_pradesh_aq_transformed.csv\n",
      "  âœ… Maharashtra: 5,869 rows -> data/processed/maharashtra_aq_transformed.csv\n",
      "  âœ… Meghalaya: 4,762 rows -> data/processed/meghalaya_aq_transformed.csv\n",
      "  âœ… Mizoram: 2,294 rows -> data/processed/mizoram_aq_transformed.csv\n",
      "  âœ… Nagaland: 2,456 rows -> data/processed/nagal_aq_transformed.csv\n",
      "  âœ… Odisha: 7,183 rows -> data/processed/odisha_aq_transformed.csv\n",
      "  âœ… Punjab: 11,568 rows -> data/processed/punjab_aq_transformed.csv\n",
      "  âœ… Rajasthan: 7,169 rows -> data/processed/rajasthan_aq_transformed.csv\n",
      "  âœ… Odisha: 7,183 rows -> data/processed/odisha_aq_transformed.csv\n",
      "  âœ… Punjab: 11,568 rows -> data/processed/punjab_aq_transformed.csv\n",
      "  âœ… Rajasthan: 7,169 rows -> data/processed/rajasthan_aq_transformed.csv\n",
      "  âœ… Sikkim: 2,413 rows -> data/processed/sikkim_aq_transformed.csv\n",
      "\n",
      "ðŸŽ‰ All transformed data saved to 'data/processed' directory!\n",
      "ðŸŽ‰ TOTAL RECORDS PRESERVED: 109,501\n",
      "  âœ… Sikkim: 2,413 rows -> data/processed/sikkim_aq_transformed.csv\n",
      "\n",
      "ðŸŽ‰ All transformed data saved to 'data/processed' directory!\n",
      "ðŸŽ‰ TOTAL RECORDS PRESERVED: 109,501\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Save Final Transformed Dataset (COMPLETE)\n",
    "\n",
    "if 'transformed_df' in dir() and len(transformed_df) > 0:\n",
    "    # Create output directory for processed data\n",
    "    processed_dir = \"data/processed\"\n",
    "    os.makedirs(processed_dir, exist_ok=True)\n",
    "    \n",
    "    # Define column order for the final output\n",
    "    index_cols = ['state', 'district', 'location_id', 'location_name', \n",
    "                  'datetime_utc', 'datetime_local', 'latitude', 'longitude']\n",
    "    \n",
    "    # Parameter columns in desired order\n",
    "    param_order = ['pm25', 'pm10', 'no2', 'co', 'so2', 'o3', \n",
    "                   'temperature', 'humidity', 'wind_speed', 'wind_direction']\n",
    "    \n",
    "    # Get existing parameter columns in order\n",
    "    existing_params = [col for col in param_order if col in transformed_df.columns]\n",
    "    \n",
    "    # Get available index columns\n",
    "    available_index = [col for col in index_cols if col in transformed_df.columns]\n",
    "    \n",
    "    # Final column order\n",
    "    final_columns = available_index + existing_params\n",
    "    \n",
    "    # Reorder columns\n",
    "    final_df = transformed_df[[col for col in final_columns if col in transformed_df.columns]].copy()\n",
    "    \n",
    "    # Sort by state, district, location, and datetime\n",
    "    sort_cols = [col for col in ['state', 'district', 'location_name', 'datetime_utc'] if col in final_df.columns]\n",
    "    final_df = final_df.sort_values(sort_cols)\n",
    "    \n",
    "    # Save the COMPLETE transformed dataset\n",
    "    output_file = f\"{processed_dir}/india_aq_transformed_last30days.csv\"\n",
    "    final_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"FINAL TRANSFORMED DATASET SAVED SUCCESSFULLY!\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nðŸ“ Output file: {output_file}\")\n",
    "    print(f\"ðŸ“Š Total rows: {len(final_df):,}\")\n",
    "    print(f\"ðŸ“‹ Total columns: {len(final_df.columns)}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"Final Column Structure:\")\n",
    "    print(\"-\"*50)\n",
    "    for i, col in enumerate(final_df.columns, 1):\n",
    "        dtype = final_df[col].dtype\n",
    "        non_null = final_df[col].notna().sum()\n",
    "        print(f\"  {i:2}. {col:20s} ({dtype}) - {non_null:,} values\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"Records per State in Final Dataset:\")\n",
    "    print(\"-\"*50)\n",
    "    state_counts = final_df.groupby('state').size().sort_values(ascending=False)\n",
    "    total = 0\n",
    "    for state, count in state_counts.items():\n",
    "        print(f\"   {state}: {count:,} rows\")\n",
    "        total += count\n",
    "    print(f\"\\n   TOTAL ROWS: {total:,}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"Final Data Preview:\")\n",
    "    print(\"-\"*50)\n",
    "    print(final_df.head(10))\n",
    "    \n",
    "    # Also save state-wise transformed files\n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"Saving state-wise transformed files...\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    for state in final_df['state'].unique():\n",
    "        state_df = final_df[final_df['state'] == state]\n",
    "        state_filename = state.lower().replace(' ', '_').replace('and', '').replace('__', '_').strip('_')\n",
    "        state_file = f\"{processed_dir}/{state_filename}_aq_transformed.csv\"\n",
    "        state_df.to_csv(state_file, index=False)\n",
    "        print(f\"  âœ… {state}: {len(state_df):,} rows -> {state_file}\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ‰ All transformed data saved to '{processed_dir}' directory!\")\n",
    "    print(f\"ðŸŽ‰ TOTAL RECORDS PRESERVED: {len(final_df):,}\")\n",
    "else:\n",
    "    print(\"âŒ No transformed data to save!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
