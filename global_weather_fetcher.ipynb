{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9eb7c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Response: {'coord': {'lon': 75.8333, 'lat': 22.7179}, 'weather': [{'id': 721, 'main': 'Haze', 'description': 'haze', 'icon': '50d'}], 'base': 'stations', 'main': {'temp': 21.1, 'feels_like': 20.73, 'temp_min': 21.1, 'temp_max': 21.1, 'pressure': 1017, 'humidity': 56, 'sea_level': 1017, 'grnd_level': 953}, 'visibility': 2500, 'wind': {'speed': 1.54, 'deg': 110}, 'clouds': {'all': 39}, 'dt': 1764561705, 'sys': {'type': 1, 'id': 9067, 'country': 'IN', 'sunrise': 1764552028, 'sunset': 1764591073}, 'timezone': 19800, 'id': 1269743, 'name': 'Indore', 'cod': 200}\n",
      "     City  Temperature (°C)  Humidity (%)  Wind Speed (m/s)  \\\n",
      "0  Indore              21.1            56              1.54   \n",
      "\n",
      "   Wind Direction (°)                  Timestamp  \n",
      "0                 110 2025-12-01 09:33:35.598986  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "API_KEY = \"eee0f55dccceb67630a015d0577f12cb\"\n",
    "CITY = \"Indore\"\n",
    "URL = f\"https://api.openweathermap.org/data/2.5/weather?q={CITY}&appid={API_KEY}&units=metric\"\n",
    "\n",
    "response = requests.get(URL)\n",
    "data = response.json()\n",
    "\n",
    "print(\"API Response:\", data)   # Debug line\n",
    "\n",
    "if \"main\" in data and \"wind\" in data:\n",
    "    weather = {\n",
    "        \"City\": CITY,\n",
    "        \"Temperature (°C)\": data[\"main\"][\"temp\"],\n",
    "        \"Humidity (%)\": data[\"main\"][\"humidity\"],\n",
    "        \"Wind Speed (m/s)\": data[\"wind\"][\"speed\"],\n",
    "        \"Wind Direction (°)\": data[\"wind\"].get(\"deg\", None),\n",
    "        \"Timestamp\": datetime.now()\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame([weather])\n",
    "    print(df)\n",
    "\n",
    "else:\n",
    "    print(\"❌ Error:\", data.get(\"message\", \"Unknown error\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d911b4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'population'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\codes\\brain tumor project yz\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'population'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Filter population ≥100,000\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m df_major \u001b[38;5;241m=\u001b[39m df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpopulation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100000\u001b[39m]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Sort by population (descending)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m df_major \u001b[38;5;241m=\u001b[39m df_major\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpopulation\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32md:\\codes\\brain tumor project yz\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\codes\\brain tumor project yz\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'population'"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "CITY_LIST_FILE = \"D:\\\\codes\\\\brain tumor project yz\\\\infosys\\\\city.list.json.gz\"\n",
    "\n",
    "# Load file\n",
    "with gzip.open(CITY_LIST_FILE, \"rt\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter population ≥100,000\n",
    "df_major = df[df[\"population\"] >= 100000]\n",
    "\n",
    "# Sort by population (descending)\n",
    "df_major = df_major.sort_values(by=\"population\", ascending=False)\n",
    "\n",
    "# Select top 1200 cities\n",
    "df_major_1200 = df_major.head(1200)\n",
    "\n",
    "# Save only ID column (for API use)\n",
    "df_major_1200.to_csv(\"major_city_ids.csv\", index=False)\n",
    "\n",
    "print(\"Saved major_city_ids.csv\")\n",
    "print(df_major_1200.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90eb253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "API_KEY = \"eee0f55dccceb67630a015d0577f12cb\"\n",
    "\n",
    "# Load list of 1200 city IDs\n",
    "all_city_ids = [...]   # paste your 1200 IDs here\n",
    "\n",
    "weather_data = []\n",
    "\n",
    "for idx, city_id in enumerate(all_city_ids):\n",
    "    \n",
    "    url = f\"http://api.openweathermap.org/data/2.5/weather?id={city_id}&appid={API_KEY}&units=metric\"\n",
    "    response = requests.get(url).json()\n",
    "\n",
    "    if \"main\" in response:\n",
    "        weather = {\n",
    "            \"City\": response[\"name\"],\n",
    "            \"Temperature (°C)\": response[\"main\"][\"temp\"],\n",
    "            \"Humidity (%)\": response[\"main\"][\"humidity\"],\n",
    "            \"Wind Speed (m/s)\": response[\"wind\"][\"speed\"],\n",
    "            \"Wind Direction (°)\": response[\"wind\"].get(\"deg\", None),\n",
    "            \"Timestamp\": datetime.now()\n",
    "        }\n",
    "        weather_data.append(weather)\n",
    "        print(f\"Fetched: {response['name']}  ({idx+1}/{len(all_city_ids)})\")\n",
    "    else:\n",
    "        print(\"Error:\", response)\n",
    "\n",
    "    time.sleep(1)   # Required (avoid rate limit)\n",
    "\n",
    "df = pd.DataFrame(weather_data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d64b2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading city list...\n",
      "Downloaded 209579 cities.\n",
      "Sampled 1200 city IDs.\n",
      "Fetching weather in 60 batches...\n",
      "Fetching weather batches...\n",
      "Fetching batch 1 → 20 cities\n",
      "Fetching batch 2 → 20 cities\n",
      "Fetching batch 3 → 20 cities\n",
      "Fetching batch 4 → 20 cities\n",
      "Fetching batch 5 → 20 cities\n",
      "Fetching batch 6 → 20 cities\n",
      "Fetching batch 7 → 20 cities\n",
      "Fetching batch 8 → 20 cities\n",
      "Fetching batch 9 → 20 cities\n",
      "Fetching batch 10 → 20 cities\n",
      "Fetching batch 11 → 20 cities\n",
      "Fetching batch 12 → 20 cities\n",
      "Fetching batch 13 → 20 cities\n",
      "Fetching batch 14 → 20 cities\n",
      "Fetching batch 15 → 20 cities\n",
      "Fetching batch 16 → 20 cities\n",
      "Fetching batch 17 → 20 cities\n",
      "Fetching batch 18 → 20 cities\n",
      "Fetching batch 19 → 20 cities\n",
      "Fetching batch 20 → 20 cities\n",
      "Fetching batch 21 → 20 cities\n",
      "Fetching batch 22 → 20 cities\n",
      "Fetching batch 23 → 20 cities\n",
      "Fetching batch 24 → 20 cities\n",
      "Fetching batch 25 → 20 cities\n",
      "Fetching batch 26 → 20 cities\n",
      "Fetching batch 27 → 20 cities\n",
      "Fetching batch 28 → 20 cities\n",
      "Fetching batch 29 → 20 cities\n",
      "Fetching batch 30 → 20 cities\n",
      "Fetching batch 31 → 20 cities\n",
      "Fetching batch 32 → 20 cities\n",
      "Fetching batch 33 → 20 cities\n",
      "Fetching batch 34 → 20 cities\n",
      "Fetching batch 35 → 20 cities\n",
      "Fetching batch 36 → 20 cities\n",
      "Fetching batch 37 → 20 cities\n",
      "Fetching batch 38 → 20 cities\n",
      "Fetching batch 39 → 20 cities\n",
      "Fetching batch 40 → 20 cities\n",
      "Fetching batch 41 → 20 cities\n",
      "Fetching batch 42 → 20 cities\n",
      "Fetching batch 43 → 20 cities\n",
      "Fetching batch 44 → 20 cities\n",
      "Fetching batch 45 → 20 cities\n",
      "Fetching batch 46 → 20 cities\n",
      "Fetching batch 47 → 20 cities\n",
      "Fetching batch 48 → 20 cities\n",
      "Fetching batch 49 → 20 cities\n",
      "Fetching batch 50 → 20 cities\n",
      "Fetching batch 51 → 20 cities\n",
      "Fetching batch 52 → 20 cities\n",
      "Fetching batch 53 → 20 cities\n",
      "Fetching batch 54 → 20 cities\n",
      "Fetching batch 55 → 20 cities\n",
      "Fetching batch 56 → 20 cities\n",
      "Fetching batch 57 → 20 cities\n",
      "Fetching batch 58 → 20 cities\n",
      "Fetching batch 59 → 20 cities\n",
      "Fetching batch 60 → 20 cities\n",
      "Error fetching batch 60: fetch_batch() takes 1 positional argument but 2 were given\n",
      "No weather data fetched. Check API key and limits.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Corrected + improved version with visualization support (world map using plotly)\n",
    "\n",
    "import requests\n",
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from itertools import islice\n",
    "import plotly.express as px\n",
    "\n",
    "# -------- CONFIG --------\n",
    "API_KEY = \"495ba73cba95e25b95cfaed153ef1c2d\"   \n",
    "CITY_LIST_URL = \"http://bulk.openweathermap.org/sample/city.list.json.gz\"\n",
    "OUTPUT_CSV = \"global_weather_data.csv\"\n",
    "NUM_CITIES = 1200  ##60 calls/min × 20 IDs/call\n",
    "BATCH_SIZE = 20\n",
    "REQUEST_DELAY = 1.0\n",
    "TIMEOUT = 15\n",
    "# ------------------------\n",
    "\n",
    "def chunks(iterable, size):\n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "        chunk = list(islice(it, size))\n",
    "        if not chunk:\n",
    "            break\n",
    "        yield chunk\n",
    "\n",
    "def download_city_list(url=CITY_LIST_URL):\n",
    "    print(\"Downloading city list...\")\n",
    "    r = requests.get(url, stream=True, timeout=TIMEOUT)\n",
    "    r.raise_for_status()\n",
    "    with gzip.GzipFile(fileobj=r.raw) as f:\n",
    "        data = json.load(f)\n",
    "    print(f\"Downloaded {len(data)} cities.\")\n",
    "    return data\n",
    "\n",
    "def sample_city_ids(city_list, n=NUM_CITIES, seed=42):\n",
    "    ids = [c[\"id\"] for c in city_list if \"id\" in c]\n",
    "    n = min(n, len(ids))\n",
    "    random.Random(seed).shuffle(ids)\n",
    "    sampled = ids[:n]\n",
    "    print(f\"Sampled {len(sampled)} city IDs.\")\n",
    "    return sampled\n",
    "\n",
    "def fetch_batch(city_ids):\n",
    "    ids = \",\".join(map(str, city_ids))\n",
    "    url = f\"https://api.openweathermap.org/data/2.5/group?id={ids}&appid={API_KEY}\"\n",
    "    return requests.get(url).json()\n",
    "\n",
    "def parse_weather_item(item):\n",
    "    return {\n",
    "        \"city_id\": item.get(\"id\"),\n",
    "        \"city\": item.get(\"name\"),\n",
    "        \"country\": item.get(\"sys\", {}).get(\"country\"),\n",
    "        \"lat\": item.get(\"coord\", {}).get(\"lat\"),\n",
    "        \"lon\": item.get(\"coord\", {}).get(\"lon\"),\n",
    "        \"temperature_C\": item.get(\"main\", {}).get(\"temp\"),\n",
    "        \"humidity_pct\": item.get(\"main\", {}).get(\"humidity\"),\n",
    "        \"pressure_hPa\": item.get(\"main\", {}).get(\"pressure\"),\n",
    "        \"wind_speed_m_s\": item.get(\"wind\", {}).get(\"speed\"),\n",
    "        \"wind_deg\": item.get(\"wind\", {}).get(\"deg\"),\n",
    "        \"weather_main\": item.get(\"weather\", [{}])[0].get(\"main\"),\n",
    "        \"weather_description\": item.get(\"weather\", [{}])[0].get(\"description\"),\n",
    "        \"timestamp_utc\": datetime.utcfromtimestamp(item.get(\"dt\")) if item.get(\"dt\") else None,\n",
    "        \"fetched_at\": datetime.utcnow()\n",
    "    }\n",
    "\n",
    "def visualize_world_map(df):\n",
    "    fig = px.scatter_geo(\n",
    "        df,\n",
    "        lat=\"lat\",\n",
    "        lon=\"lon\",\n",
    "        color=\"temperature_C\",\n",
    "        hover_name=\"city\",\n",
    "        hover_data=[\"country\", \"humidity_pct\", \"wind_speed_m_s\", \"weather_main\"],\n",
    "        projection=\"natural earth\",\n",
    "        title=\"Global Weather Visualization (Temperature Colored)\"\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "def main():\n",
    "    city_list = download_city_list()\n",
    "    sampled_ids = sample_city_ids(city_list, NUM_CITIES)\n",
    "\n",
    "    all_records = []\n",
    "    total_batches = (len(sampled_ids) + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "\n",
    "    print(f\"Fetching weather in {total_batches} batches...\")\n",
    "\n",
    "    print(\"Fetching weather batches...\")\n",
    "\n",
    "    for i in range(0, len(sampled_ids), 20):\n",
    "        batch = sampled_ids[i:i+20]\n",
    "        print(f\"Fetching batch {i//20 + 1} → {len(batch)} cities\")\n",
    "\n",
    "    try:\n",
    "        data = fetch_batch(batch, API_KEY)\n",
    "        for item in data.get(\"list\", []):\n",
    "            all_records.append(parse_weather_item(item))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching batch {i//20 + 1}: {e}\")\n",
    "    \n",
    "    time.sleep(1)   # rate limit protection\n",
    "\n",
    "\n",
    "    if all_records:\n",
    "        df = pd.DataFrame(all_records)\n",
    "        df.to_csv(OUTPUT_CSV, index=False)\n",
    "        print(f\"Saved {len(df)} records → {OUTPUT_CSV}\")\n",
    "        visualize_world_map(df)\n",
    "    else:\n",
    "        print(\"No weather data fetched. Check API key and limits.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eb12395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cod': 401, 'message': 'Invalid API key. Please see https://openweathermap.org/faq#error401 for more info.'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.openweathermap.org/data/2.5/group?id=1275841&appid=eee0f55dccceb67630a015d0577f12cb\"\n",
    "print(requests.get(url).json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebfbd14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "636c4c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id           name state country                                 coord\n",
      "0   833.0  Ḩeşār-e Sefīd            IR  {'lon': 47.159401, 'lat': 34.330502}\n",
      "1  2960.0   ‘Ayn Ḩalāqīm            SY  {'lon': 36.321911, 'lat': 34.940079}\n",
      "2  3245.0         Taglag            IR   {'lon': 44.98333, 'lat': 38.450001}\n",
      "3  3530.0       Qabāghlū            IR  {'lon': 46.168499, 'lat': 36.173302}\n",
      "4  5174.0        ‘Arīqah            SY   {'lon': 36.48336, 'lat': 32.889809}\n",
      "Total cities: 209579\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "# Load the major cities list\n",
    "with gzip.open(\"D:\\\\codes\\\\brain tumor project yz\\\\infosys\\\\city.list.json.gz\", \"rt\", encoding=\"utf-8\") as f:\n",
    "    cities = json.load(f)\n",
    "\n",
    "df_cities = pd.DataFrame(cities)\n",
    "print(df_cities.head())\n",
    "print(\"Total cities:\", len(df_cities))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a540d503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total major cities selected: 0\n",
      "\n",
      "✔ COMPLETED!\n",
      "File saved as: global_major_cities_weather.csv\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d808aaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected cities found: 91\n",
      "Fetching 1/91 → Dubai, AE\n",
      "Fetching 2/91 → Dubai, AE\n",
      "Fetching 3/91 → Cairo, EG\n",
      "Fetching 4/91 → Moscow, RU\n",
      "Fetching 5/91 → Moscow, RU\n",
      "Fetching 6/91 → Istanbul, TR\n",
      "Fetching 7/91 → Karachi, PK\n",
      "Fetching 8/91 → Hyderabad, PK\n",
      "Fetching 9/91 → Dhaka, BD\n",
      "Fetching 10/91 → Chennai, IN\n",
      "Fetching 11/91 → Hyderabad, IN\n",
      "Fetching 12/91 → Delhi, IN\n",
      "Fetching 13/91 → Kolkata, IN\n",
      "Fetching 14/91 → Mumbai, IN\n",
      "Fetching 15/91 → Bengaluru, IN\n",
      "Fetching 16/91 → Dhaka, BD\n",
      "Fetching 17/91 → Bangkok, TH\n",
      "Fetching 18/91 → Bangkok, TH\n",
      "Fetching 19/91 → Jakarta, ID\n",
      "Fetching 20/91 → Manila, PH\n",
      "Fetching 21/91 → Los Angeles, PH\n",
      "Fetching 22/91 → Shanghai, CN\n",
      "Fetching 23/91 → Beijing, CN\n",
      "Fetching 24/91 → Hong Kong, HK\n",
      "Fetching 25/91 → Seoul, KR\n",
      "Fetching 26/91 → Seoul, KR\n",
      "Fetching 27/91 → Tokyo, JP\n",
      "Fetching 28/91 → Osaka, JP\n",
      "Fetching 29/91 → Osaka, JP\n",
      "Fetching 30/91 → Sydney, AU\n",
      "Fetching 31/91 → Melbourne, AU\n",
      "Fetching 32/91 → Lagos, PT\n",
      "Fetching 33/91 → Lagos, NG\n",
      "Fetching 34/91 → Melbourne, GB\n",
      "Fetching 35/91 → Melbourne, GB\n",
      "Fetching 36/91 → London, GB\n",
      "Fetching 37/91 → Paris, FR\n",
      "Fetching 38/91 → Paris, FR\n",
      "Fetching 39/91 → Paris, FR\n",
      "Fetching 40/91 → Buenos Aires, AR\n",
      "Fetching 41/91 → Buenos Aires, AR\n",
      "Fetching 42/91 → São Paulo, BR\n",
      "Fetching 43/91 → São Paulo, BR\n",
      "Fetching 44/91 → Rio de Janeiro, BR\n",
      "Fetching 45/91 → Rio de Janeiro, BR\n",
      "Fetching 46/91 → Mexico City, MX\n",
      "Fetching 47/91 → Buenos Aires, HN\n",
      "Fetching 48/91 → Buenos Aires, NI\n",
      "Fetching 49/91 → Buenos Aires, CR\n",
      "Fetching 50/91 → Buenos Aires, CO\n",
      "Fetching 51/91 → Buenos Aires, PE\n",
      "Fetching 52/91 → Buenos Aires, VE\n",
      "Fetching 53/91 → Buenos Aires, MX\n",
      "Fetching 54/91 → Cairo, US\n",
      "Fetching 55/91 → London, US\n",
      "Fetching 56/91 → Manila, US\n",
      "Fetching 57/91 → Melbourne, US\n",
      "Fetching 58/91 → Paris, US\n",
      "Fetching 59/91 → Melbourne, US\n",
      "Fetching 60/91 → Cairo, US\n",
      "Fetching 61/91 → Cairo, US\n",
      "Fetching 62/91 → Paris, US\n",
      "Fetching 63/91 → London, US\n",
      "Fetching 64/91 → Paris, US\n",
      "Fetching 65/91 → Delhi, US\n",
      "Fetching 66/91 → Paris, US\n",
      "Fetching 67/91 → London, US\n",
      "Fetching 68/91 → Paris, US\n",
      "Fetching 69/91 → Paris, US\n",
      "Fetching 70/91 → Paris, US\n",
      "Fetching 71/91 → London, US\n",
      "Fetching 72/91 → Cairo, US\n",
      "Fetching 73/91 → Delhi, US\n",
      "Fetching 74/91 → New York, US\n",
      "Fetching 75/91 → Moscow, US\n",
      "Fetching 76/91 → Delhi, US\n",
      "Fetching 77/91 → London, US\n",
      "Fetching 78/91 → Los Angeles, US\n",
      "Fetching 79/91 → Moscow, US\n",
      "Fetching 80/91 → Paris, US\n",
      "Fetching 81/91 → Cairo, US\n",
      "Fetching 82/91 → Manila, US\n",
      "Fetching 83/91 → Delhi, CA\n",
      "Fetching 84/91 → London, CA\n",
      "Fetching 85/91 → Sydney, CA\n",
      "Fetching 86/91 → Sydney, CA\n",
      "Fetching 87/91 → Paris, FR\n",
      "Fetching 88/91 → Buenos Aires, PE\n",
      "Fetching 89/91 → Paris, CA\n",
      "Fetching 90/91 → Melbourne, AU\n",
      "Fetching 91/91 → Lagos, PT\n",
      "✔ Completed!\n",
      "Saved: global_major_cities_weather.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "import gzip\n",
    "\n",
    "API_KEY = \"eee0f55dccceb67630a015d0577f12cb\"\n",
    "\n",
    "CITY_FILE = r\"D:\\\\codes\\\\brain tumor project yz\\\\infosys\\\\city.list.json.gz\"\n",
    "\n",
    "# ---- Load city list ----\n",
    "with gzip.open(CITY_FILE, \"rt\", encoding=\"utf-8\") as f:\n",
    "    cities = json.load(f)\n",
    "\n",
    "# ---- List of major global cities ----\n",
    "TOP_CITIES = [\n",
    "    \"Tokyo\", \"Delhi\", \"Shanghai\", \"São Paulo\", \"Mumbai\", \"Mexico City\", \"Osaka\",\n",
    "    \"Cairo\", \"New York\", \"Beijing\", \"Karachi\", \"Buenos Aires\", \"Istanbul\",\n",
    "    \"Manila\", \"Lagos\", \"Rio de Janeiro\", \"Los Angeles\", \"Moscow\", \"Paris\",\n",
    "    \"London\", \"Dhaka\", \"Jakarta\", \"Bangkok\", \"Dubai\", \"Seoul\", \"Hong Kong\",\n",
    "    \"Chennai\", \"Hyderabad\", \"Bengaluru\", \"Kolkata\", \"Sydney\", \"Melbourne\"\n",
    "]\n",
    "\n",
    "# Match these city names with the list → get their city IDs\n",
    "selected_ids = []\n",
    "for city in cities:\n",
    "    if city[\"name\"] in TOP_CITIES:\n",
    "        selected_ids.append((city[\"id\"], city[\"name\"], city[\"country\"]))\n",
    "\n",
    "print(f\"Selected cities found: {len(selected_ids)}\")\n",
    "\n",
    "weather_data = []\n",
    "\n",
    "# ---- Fetch Weather ----\n",
    "for i, (city_id, name, country) in enumerate(selected_ids):\n",
    "    print(f\"Fetching {i+1}/{len(selected_ids)} → {name}, {country}\")\n",
    "\n",
    "    url = f\"https://api.openweathermap.org/data/2.5/weather?id={city_id}&appid={API_KEY}&units=metric\"\n",
    "    \n",
    "    try:\n",
    "        res = requests.get(url)\n",
    "        data = res.json()\n",
    "\n",
    "        if \"main\" in data:\n",
    "            weather_data.append({\n",
    "                \"City\": name,\n",
    "                \"Country\": country,\n",
    "                \"Latitude\": data[\"coord\"][\"lat\"],\n",
    "                \"Longitude\": data[\"coord\"][\"lon\"],\n",
    "                \"Temperature (°C)\": data[\"main\"][\"temp\"],\n",
    "                \"Humidity (%)\": data[\"main\"][\"humidity\"],\n",
    "                \"Wind Speed (m/s)\": data[\"wind\"][\"speed\"],\n",
    "                \"Weather\": data[\"weather\"][0][\"description\"],\n",
    "                \"Timestamp\": datetime.utcnow()\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "# ---- Save CSV ----\n",
    "df = pd.DataFrame(weather_data)\n",
    "df.to_csv(\"global_major_cities_weather.csv\", index=False)\n",
    "\n",
    "print(\"✔ Completed!\")\n",
    "print(\"Saved: global_major_cities_weather.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8443c3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Cities Loaded: 30000\n",
      "Fetched weather for 100 cities...\n",
      "Fetched weather for 200 cities...\n",
      "Fetched weather for 300 cities...\n",
      "Fetched weather for 400 cities...\n",
      "Fetched weather for 500 cities...\n",
      "Fetched weather for 600 cities...\n",
      "Fetched weather for 700 cities...\n",
      "Fetched weather for 800 cities...\n",
      "Fetched weather for 900 cities...\n",
      "Fetched weather for 1000 cities...\n",
      "Fetched weather for 1100 cities...\n",
      "Fetched weather for 1200 cities...\n",
      "Fetched weather for 1300 cities...\n",
      "Fetched weather for 1400 cities...\n",
      "Fetched weather for 1500 cities...\n",
      "Fetched weather for 1600 cities...\n",
      "Fetched weather for 1700 cities...\n",
      "Fetched weather for 1800 cities...\n",
      "Fetched weather for 1900 cities...\n",
      "Fetched weather for 2000 cities...\n",
      "Fetched weather for 2100 cities...\n",
      "Fetched weather for 2200 cities...\n",
      "Fetched weather for 2300 cities...\n",
      "Fetched weather for 2400 cities...\n",
      "Fetched weather for 2500 cities...\n",
      "Fetched weather for 2600 cities...\n",
      "Fetched weather for 2700 cities...\n",
      "Fetched weather for 2800 cities...\n",
      "Fetched weather for 2900 cities...\n",
      "Fetched weather for 3000 cities...\n",
      "Fetched weather for 3100 cities...\n",
      "Fetched weather for 3200 cities...\n",
      "Fetched weather for 3300 cities...\n",
      "Fetched weather for 3400 cities...\n",
      "Fetched weather for 3500 cities...\n",
      "Fetched weather for 3600 cities...\n",
      "Fetched weather for 3700 cities...\n",
      "Fetched weather for 3800 cities...\n",
      "Fetched weather for 3900 cities...\n",
      "Fetched weather for 4000 cities...\n",
      "Fetched weather for 4100 cities...\n",
      "Fetched weather for 4200 cities...\n",
      "Fetched weather for 4300 cities...\n",
      "Fetched weather for 4400 cities...\n",
      "Fetched weather for 4500 cities...\n",
      "Fetched weather for 4600 cities...\n",
      "Fetched weather for 4700 cities...\n",
      "Fetched weather for 4800 cities...\n",
      "Fetched weather for 4900 cities...\n",
      "Fetched weather for 5000 cities...\n",
      "Fetched weather for 5100 cities...\n",
      "Fetched weather for 5200 cities...\n",
      "Fetched weather for 5300 cities...\n",
      "Fetched weather for 5400 cities...\n",
      "Fetched weather for 5500 cities...\n",
      "Fetched weather for 5600 cities...\n",
      "Fetched weather for 5700 cities...\n",
      "Fetched weather for 5800 cities...\n",
      "Fetched weather for 5900 cities...\n",
      "Fetched weather for 6000 cities...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# -----------------------------------------\n",
    "# STEP 1 — Load the 30K global cities dataset\n",
    "# -----------------------------------------\n",
    "cities = pd.read_csv(\n",
    "    \"D:\\codes\\\\brain tumor project yz\\\\infosys\\\\cities5000.txt\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"geonameid\", \"name\", \"asciiname\", \"alternatenames\",\n",
    "        \"latitude\", \"longitude\", \"feature_class\", \"feature_code\",\n",
    "        \"country_code\", \"cc2\", \"admin1\", \"admin2\", \"admin3\",\n",
    "        \"admin4\", \"population\", \"elevation\", \"dem\",\n",
    "        \"timezone\", \"modification\"\n",
    "    ],\n",
    "    dtype=str\n",
    ")\n",
    "\n",
    "# Keep only useful columns\n",
    "cities = cities[[\"name\", \"country_code\", \"latitude\", \"longitude\", \"population\"]]\n",
    "\n",
    "# Keep cities with population available\n",
    "cities = cities.dropna(subset=[\"latitude\", \"longitude\"])\n",
    "\n",
    "# Convert latitude/longitude\n",
    "cities[\"latitude\"] = cities[\"latitude\"].astype(float)\n",
    "cities[\"longitude\"] = cities[\"longitude\"].astype(float)\n",
    "\n",
    "# Keep top 30,000 cities\n",
    "cities = cities.head(30000)\n",
    "\n",
    "print(\"Total Cities Loaded:\", len(cities))\n",
    "\n",
    "# -----------------------------------------\n",
    "# STEP 2 — Fetch Weather from Open-Meteo\n",
    "# -----------------------------------------\n",
    "weather_data = []\n",
    "\n",
    "def get_weather(lat, lon):\n",
    "    url = f\"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&current_weather=true\"\n",
    "\n",
    "    try:\n",
    "        res = requests.get(url, timeout=10)\n",
    "        data = res.json()\n",
    "\n",
    "        if \"current_weather\" not in data:\n",
    "            return None\n",
    "\n",
    "        w = data[\"current_weather\"]\n",
    "\n",
    "        return {\n",
    "            \"Temperature (°C)\": w.get(\"temperature\"),\n",
    "            \"Wind Speed (m/s)\": w.get(\"windspeed\"),\n",
    "            \"Wind Direction (°)\": w.get(\"winddirection\"),\n",
    "            \"Timestamp\": datetime.utcnow()\n",
    "        }\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# -----------------------------------------\n",
    "# STEP 3 — Loop cities with safe rate\n",
    "# -----------------------------------------\n",
    "count = 0\n",
    "\n",
    "for idx, row in cities.iterrows():\n",
    "    city = row[\"name\"]\n",
    "    country = row[\"country_code\"]\n",
    "    lat = row[\"latitude\"]\n",
    "    lon = row[\"longitude\"]\n",
    "\n",
    "    weather = get_weather(lat, lon)\n",
    "\n",
    "    if weather:\n",
    "        record = {\n",
    "            \"City\": city,\n",
    "            \"Country\": country,\n",
    "            \"Latitude\": lat,\n",
    "            \"Longitude\": lon,\n",
    "            \"Temperature (°C)\": weather[\"Temperature (°C)\"],\n",
    "            \"Humidity (%)\": None,           # free API does not provide (optional field)\n",
    "            \"Wind Speed (m/s)\": weather[\"Wind Speed (m/s)\"],\n",
    "            \"Wind Direction (°)\": weather[\"Wind Direction (°)\"],\n",
    "            \"Timestamp\": weather[\"Timestamp\"],\n",
    "        }\n",
    "\n",
    "        weather_data.append(record)\n",
    "        count += 1\n",
    "\n",
    "    if count % 100 == 0:\n",
    "        print(f\"Fetched weather for {count} cities...\")\n",
    "\n",
    "    time.sleep(0.2)  # avoid too many requests\n",
    "\n",
    "# -----------------------------------------\n",
    "# STEP 4 — Save to CSV\n",
    "# -----------------------------------------\n",
    "df_weather = pd.DataFrame(weather_data)\n",
    "df_weather.to_csv(\"global_30k_weather.csv\", index=False)\n",
    "\n",
    "print(\"\\n✔ COMPLETED!\")\n",
    "print(\"Total cities with weather data:\", len(df_weather))\n",
    "print(\"File saved as: global_30k_weather.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d03ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
